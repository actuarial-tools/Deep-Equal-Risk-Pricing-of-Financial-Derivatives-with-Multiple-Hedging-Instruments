{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Equal Risk Pricing of Financial Derivatives with Multiple Hedging Instruments \n",
    "This notebook presents an example of implementation of the equal risk pricing framework as presented in Carbonneau and Godin (2021). \n",
    "- The equal risk option price $C_{0}^{\\star}$ and the measure of market incompleteness $\\epsilon^{\\star}$ are computed for an at-the-money European-type put option of maturity 1 year under the Merton jump-diffusion model. \n",
    "- The deep hedging algorithm of Buehler et al. (2019) is applied twice to train two distinct long-short term memory which are used to approximate the optimal hedging strategy respectively for the long and the short position in the derivative.\n",
    "- The convex risk measure used to quantity the residual risk is the Conditional Value-at-Risk with alpha = 0.95. \n",
    "- For a complete description of the algorithm, the reader is referred to Section 3 and to the pseudo-algorithm in Appendix B. \n",
    "\n",
    "Note: some parts of the code are inspired by the following implementation of the deep hedging algorithm: \n",
    "    - https://nbviewer.jupyter.org/urls/people.math.ethz.ch/~jteichma/lecture_ml_web/lecture_3.ipynb\n",
    "    - https://github.com/mgroncki/DataScienceNotebooks/blob/master/DeepHedging/DeepHedging_Part1.ipynb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "np.seterr(divide = 'ignore') \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from scipy import stats\n",
    "from scipy.stats import skew\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Deep hedging class\n",
    "- This class implements the deep hedging algorithm with a long-short term memory (LSTM) under the CVaR risk measure\n",
    "- Can be applied for hedging with the underlying (daily and month basis) or with two options.\n",
    "- Works for both long and short position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepAgent(object):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    nbs_point_traj       : if [S_0,...,S_N], nbs_point_traj = N+1\n",
    "    batch_size           : Size of the batch\n",
    "    nbs_input            : Nbs of features of the neural networks\n",
    "        - This is prior to adding V_{t} at each-timestep\n",
    "        - Depends on which asset (stock or options) is used\n",
    "    loss_type            : Loss function applied on the rewards {MSE, SMSE}\n",
    "    nbs_assets           : Number of hedging instruments\n",
    "    position_type        : {Long, Short}\n",
    "    hidden_layers        : Number of LSTM cells\n",
    "    nbs_units            : Fixed number of units per layer\n",
    "    lr                   : Learning rate\n",
    "    prepro_stock         : preprocessing of stock prices {Log-moneyness, Nothing}.\n",
    "    hedging_instruments  : {\"Stock\", \"ATM call and put\"}\n",
    "    name                 : Model name to be saved\n",
    "    alpha                : risk aversion parameter of CVaR\n",
    "    \"\"\"\n",
    "    def __init__(self, nbs_point_traj, batch_size, nbs_input, loss_type, nbs_assets, position_type,\n",
    "                 nbs_layers, nbs_units, lr, prepro_risky_assets, hedging_instruments, alpha, name='model'):\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        self.nbs_point_traj            = nbs_point_traj\n",
    "        self.batch_size                = batch_size\n",
    "        self.nbs_input                 = nbs_input\n",
    "        self.loss_type                 = loss_type\n",
    "        self.nbs_assets                = nbs_assets\n",
    "        self.position_type             = position_type\n",
    "        self.nbs_layers                = nbs_layers\n",
    "        self.nbs_units                 = nbs_units\n",
    "        self.lr                        = lr\n",
    "        self.prepro_stock              = prepro_stock\n",
    "        self.hedging_instruments       = hedging_instruments\n",
    "        self.alpha                     = alpha\n",
    "        self.strike                    = tf.ones(self.batch_size)*strike\n",
    "        \n",
    "        # 1) Placeholder - Stock price is normalized!\n",
    "        # self.input:\n",
    "        # - [S_t, IV_t, ..., T-t];\n",
    "        #   - S_t  : price of the underlying \n",
    "        #   - IV_t : implied vol\n",
    "        self.input        = tf.placeholder(tf.float32, [nbs_point_traj, batch_size, nbs_input])  # Stock prices are normalized here                   \n",
    "        self.disc_tensor  = tf.placeholder(tf.float32, [nbs_point_traj, batch_size, 1]) # To discount from 't' to 0.\n",
    "        self.deltas       = tf.zeros(shape = [nbs_point_traj-1, batch_size, 1], dtype=tf.float32)\n",
    "                \n",
    "        if(self.hedging_instruments == \"ATM call and put\"):\n",
    "            self.opts_price = tf.placeholder(tf.float32, [nbs_point_traj, batch_size, 2])\n",
    "        self.strategy  = tf.zeros(shape = [nbs_point_traj-1, batch_size, nbs_assets], dtype=tf.float32)\n",
    "    \n",
    "        # 2) Store prices of the underlying unormalized\n",
    "        self.underlying_unorm_prices = self.inverse_processing(self.input[:,:,0])   \n",
    "         \n",
    "        # 3) Store the unormalized hedging instrument prices\n",
    "        if(self.nbs_assets ==1):\n",
    "            if(self.hedging_instruments == \"Stock\"):\n",
    "                self.unorm_hedging_inst_price_b = tf.expand_dims(self.inverse_processing(self.input[0:-1,:,0]),axis=2)\n",
    "\n",
    "                # Here, end of price is the same as the beginning of the next period\n",
    "                self.unorm_hedging_inst_price_e = tf.expand_dims(self.inverse_processing(self.input[1:,:,0]),axis=2)\n",
    "\n",
    "        elif(self.nbs_assets > 1):\n",
    "            if(self.hedging_instruments == \"ATM call and put\"):\n",
    "                self.unorm_hedging_inst_price_b = self.opts_price[0:-1,:]  # all prices except last one, useless\n",
    "                self.unorm_hedging_inst_price_e = self.payoff_liquid_inst_func()\n",
    "                  \n",
    "        # 4) Discounted difference prices of the hedging instruments\n",
    "        unorm_discount_hedging_inst_price_b = self.unorm_hedging_inst_price_b*self.disc_tensor[0:-1,:,:]\n",
    "        unorm_discount_hedging_inst_price_e = self.unorm_hedging_inst_price_e*self.disc_tensor[1:,:,:]\n",
    "        dS_hedging_inst = unorm_discount_hedging_inst_price_e - unorm_discount_hedging_inst_price_b \n",
    "        \n",
    "        # 5) Compute the hedging strategy for each time-step with the LSTM\n",
    "        lstm = tf.contrib.cudnn_rnn.CudnnLSTM(num_layers = self.nbs_layers, num_units  = self.nbs_units)\n",
    "         \n",
    "        # 5.1) Output layer - to produce the number of stocks to hold\n",
    "        W_o = tf.get_variable(name='W_o', shape=[self.nbs_assets, self.nbs_units], initializer=tf.contrib.layers.xavier_initializer())\n",
    "        b_o = tf.get_variable(name='b_o', shape=[self.nbs_assets], initializer=tf.constant_initializer(0.))\n",
    "        activation_out = None\n",
    "            \n",
    "        # 5.2) Portfolio value - updated at each time-step:\n",
    "        # - Initial price is zero\n",
    "        V_t = tf.zeros(self.batch_size)\n",
    "            \n",
    "        # 5.3) Initial time-step - must be different to include the initial-state\n",
    "        for t in range(self.nbs_point_traj-1): \n",
    "            input_t = tf.expand_dims(tf.concat([self.input[t,:,:], tf.expand_dims(V_t, axis = 1)], axis=1), axis = 0)\n",
    "            if(t==0):\n",
    "                h1, final_state = lstm(input_t)\n",
    "                    \n",
    "                # With an LSTM, the output is of shape [1, BS, 1], no need to expand_dims self.strategy\n",
    "                self.strategy = tf.tensordot(h1, W_o, axes=[[2], [1]]) + b_o\n",
    "                if activation_out is not None:\n",
    "                    self.strategy = activation_out(self.strategy)\n",
    "                        \n",
    "            else:\n",
    "                h1, final_state = lstm(input_t, initial_state = final_state)\n",
    "                output = tf.tensordot(h1, W_o, axes=[[2], [1]]) + b_o\n",
    "                if activation_out is not None:\n",
    "                    output = activation_out(output)\n",
    "                \n",
    "                # Store the resulting strategy in self.strategy\n",
    "                self.strategy = tf.concat([self.strategy, output], axis = 0)\n",
    "                    \n",
    "                # Compute the value for the next time-period\n",
    "                factor = tf.div(self.disc_tensor[t,:,0],self.disc_tensor[t+1,:,0]) # equal exp(rh)                 \n",
    "                # update rule: see Remark 2.1\n",
    "                V_t_pre = V_t\n",
    "                V_t = V_t_pre*factor + tf.reduce_sum(self.strategy[t,:,:]*(self.unorm_hedging_inst_price_e[t,:,:] - self.unorm_hedging_inst_price_b[t,:,:]*tf.expand_dims(factor, axis=1)), axis=1)\n",
    "          \n",
    "        # 6) Compute the payoff of the put to hedge \n",
    "        self.payoff = tf.maximum(self.strike - self.underlying_unorm_prices[-1,:],0)   \n",
    "        \n",
    "        # 7) Compute hedging errors\n",
    "        cumulative_factor = tf.reciprocal(self.disc_tensor[-1,:,0])  # Project from 0 to T\n",
    "        self.disc_hedging_gain = tf.reduce_sum(dS_hedging_inst*self.strategy, axis=[0,2]) # should be of [batch_size]\n",
    "        \n",
    "        if(self.position_type == 'Short'):\n",
    "            self.hedging_err = self.payoff - cumulative_factor*self.disc_hedging_gain\n",
    "        elif(self.position_type == 'Long'):\n",
    "            self.hedging_err = - self.payoff - cumulative_factor*(self.disc_hedging_gain)\n",
    "        \n",
    "        # 8) Compute the CVaR_{alpha} on the batch of hedging error\n",
    "        # - This is the empirical cost functions estimated with a mini-batch\n",
    "        # - Equivalent to estimator of CVaR_{alpha} presented in our paper\n",
    "        self.loss = tf.reduce_mean(tf.contrib.framework.sort(self.hedging_err)[tf.cast(self.alpha*self.batch_size,tf.int32):])\n",
    "        \n",
    "        # 9) SGD step with the adam optimizer\n",
    "        optimizer  = tf.train.AdamOptimizer(learning_rate = lr)  \n",
    "        self.train = optimizer.minimize(self.loss) \n",
    "       \n",
    "        # 10) Save the model\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.model_name = name\n",
    "        \n",
    "    # Given a type of preprocessing, reverse the processing of the stock price\n",
    "    def inverse_processing(self, paths):\n",
    "        if (self.prepro_stock == \"Log-moneyness\"):\n",
    "            paths = self.strike*tf.exp(paths)\n",
    "        return paths\n",
    "        \n",
    "    # ---------------------------------------------------------------------------------------# \n",
    "    # Function to call the deep hedging algorithm batch-wise\n",
    "    # Function adapted from https://github.com/mgroncki/DataScienceNotebooks/blob/master/DeepHedging/DeepHedging_Part1.ipynb \n",
    "    \"\"\"\n",
    "    Input:\n",
    "     - paths       : tensor of features of dimension [n_timesteps+1, n_sims, nbs_features]\n",
    "     - disc_batch  : tensor of discount factors of dimension [n_timesteps+1, N_batch, 1]\n",
    "     - epochs      : total number of epochs to run\n",
    "    \"\"\"\n",
    "    def train_deephedging(self, paths, disc_batch, sess, epochs, option_prices=-99999999999):\n",
    "        sample_size       = paths.shape[1]               # total number of paths in the train set\n",
    "        batch_size        = self.batch_size    \n",
    "        idx               = np.arange(sample_size)       # [0,1,...,sample_size-1]\n",
    "        start             = dt.datetime.now()            # Time-to-train\n",
    "        self.loss_epochs  = 9999999*np.ones(epochs)      # Store the loss at the end of each epoch for the train              \n",
    "        loss_best         = 999999999\n",
    "        epoch             = 0                       \n",
    "        \n",
    "        # Loop for each epoch until the maximum number of epochs\n",
    "        while (epoch < epochs):\n",
    "            hedging_err_train = []  # Store hedging errors obtained for one complete epoch \n",
    "            np.random.shuffle(idx)  # Randomize the dataset (not useful in this case since dataset is simulated iid)\n",
    "            \n",
    "            # loop over each batch size\n",
    "            for i in range(int(sample_size/batch_size)):\n",
    "                \n",
    "                # Indexes of paths used for the mini-batch\n",
    "                indices = idx[i*batch_size : (i+1)*batch_size]\n",
    "                                \n",
    "                # SGD step \n",
    "                # - if trading stock\n",
    "                if(self.hedging_instruments == \"Stock\"):\n",
    "                    _, hedging_err = sess.run([self.train, self.hedging_err], \n",
    "                                               {self.input        : paths[:,indices,:],\n",
    "                                                self.disc_tensor  : disc_batch})\n",
    "                # if trading options\n",
    "                elif(self.hedging_instruments == \"ATM call and put\"):\n",
    "                    _, hedging_err = sess.run([self.train, self.hedging_err], \n",
    "                                               {self.input        : paths[:,indices,:],\n",
    "                                                self.opts_price   : option_prices[:,indices,:],\n",
    "                                                self.disc_tensor  : disc_batch})               \n",
    "                \n",
    "                hedging_err_train.append(hedging_err)\n",
    "            \n",
    "            # Store the loss on the train set after each epoch for learning curve\n",
    "            self.loss_epochs[epoch] = self.loss_out_optim(np.concatenate(hedging_err_train))\n",
    "            if(self.loss_epochs[epoch] < loss_best):\n",
    "                loss_best = self.loss_epochs[epoch]\n",
    "                self.saver.save(sess, r\"/Users/alexa/Github files/ERP with multi hedging instruments/Models/%s/models.ckpt\" % self.model_name)\n",
    "            \n",
    "            # Print the CVaR value at the end of each epoch\n",
    "            print('Time elapsed:', dt.datetime.now()-start)\n",
    "            print('Epoch %d, CVaR - Train: %.3f' % (epoch+1, self.loss_epochs[epoch]))\n",
    "                \n",
    "            epoch+=1  # increment the epoch\n",
    "                \n",
    "        # End of training\n",
    "        print(\"---Finished training results---\")\n",
    "        print('Time elapsed:', dt.datetime.now()-start)    \n",
    "\n",
    "        # Return the learning curve \n",
    "        return self.loss_epochs\n",
    "    \n",
    "    # ---------------------------------------------------------------------------------------#\n",
    "    # Compute the payoff of the liability to hedge               \n",
    "    # - Stricly used for the case where freq obs|rebal == monthly, but payoff freq == yearly #\n",
    "    # ---------------------------------------------------------------------------------------#\n",
    "    def payoff_liquid_inst_func(self):\n",
    "        # Two ATM options at each time-step\n",
    "        payoff_call = tf.expand_dims(tf.maximum(self.underlying_unorm_prices[1:,:] - self.underlying_unorm_prices[0:-1,:], 0), axis=2)\n",
    "        payoff_put = tf.expand_dims(tf.maximum(self.underlying_unorm_prices[0:-1,:] - self.underlying_unorm_prices[1:,:],0), axis=2)\n",
    "            \n",
    "        # Compilation\n",
    "        payoff = tf.concat([payoff_call, payoff_put], axis=2)    \n",
    "        return(payoff)\n",
    "    \n",
    "    def loss_out_optim(self, hedging_err):\n",
    "        if (self.loss_type == \"CVaR\"):\n",
    "            loss = np.mean(np.sort(hedging_err)[int(self.alpha*hedging_err.shape[0]):])\n",
    "        return loss\n",
    "    \n",
    "    # option_prices: will only be used if we hedge with options\n",
    "    def training(self, paths, disc_paths, sess, epochs, \n",
    "                 option_prices=-999999999999, init=True):\n",
    "        \n",
    "        if init:\n",
    "            # for the training part, you reset all of your parameters\n",
    "            sess.run(tf.global_variables_initializer()) \n",
    "        \n",
    "        loss_epoch = self.train_deephedging(paths, disc_paths, sess, epochs, option_prices)\n",
    "\n",
    "        return loss_epoch\n",
    "        \n",
    "    def predict(self, paths, disc_paths, sess, loss_type, option_prices=-99999999):\n",
    "        sample_size = paths.shape[1]\n",
    "        batch_size=self.batch_size    \n",
    "        idx = np.arange(sample_size)  # [0,1,...,sample_size-1]\n",
    "        start = dt.datetime.now()     # compute time\n",
    "        \n",
    "        # Save the hedging Pnl for each batch      \n",
    "        hedging_err_pred = [] \n",
    "        strategy_pred = []\n",
    "            \n",
    "        # loop over sample size to do one complete epoch\n",
    "        # WATCH OUT: will use the whole dataset only if sample_size/batch_size = integer...\n",
    "        for i in range(int(sample_size/batch_size)):\n",
    "                \n",
    "            # vector of the paths we are looking at\n",
    "            indices = idx[i*batch_size : (i+1)*batch_size]\n",
    "            batch_disc = disc_paths[:,indices,:]          \n",
    "            \n",
    "            # SGD step \n",
    "            # - if trading stock\n",
    "            if(self.hedging_instruments == \"Stock\"):\n",
    "                hedging_err, strategy = sess.run([self.hedging_err, self.strategy], \n",
    "                                                 {self.input        : paths[:,indices,:],\n",
    "                                                  self.disc_tensor  : batch_disc}) \n",
    "            \n",
    "            # if trading two options\n",
    "            elif(self.hedging_instruments == \"ATM call and put\"):\n",
    "                \n",
    "                hedging_err, strategy = sess.run([self.hedging_err, self.strategy], \n",
    "                                                 {self.input        : paths[:,indices,:],\n",
    "                                                  self.opts_price   : option_prices[:,indices,:],\n",
    "                                                  self.disc_tensor  : batch_disc}) \n",
    "            \n",
    "            # This is the batch of input: (nbs_point_traj x indices x nbs_assets)\n",
    "            strategy_pred.append(strategy)\n",
    "\n",
    "        return np.concatenate(strategy_pred,axis=1)   \n",
    "         \n",
    "    def restore(self, sess, checkpoint):\n",
    "        self.saver.restore(sess, checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Construction of the train-test sets for all cases (daily|monthly underlying + two options)\n",
    "- A.1) Simulation of 500K paths under the Merton jump-diffusion model with the parameters of jump risk scenario 2: \n",
    "    - [nu, sigma, lambda_, gamma, delta] = [0.111093, 0.132288, 0.25, -0.10, 0.10]\n",
    "- A.2) Log AR(1) model for implied volatility\n",
    "    - [kappa, theta, sigma_IV, IV_0] = [0.15, np.log(0.15), 0.06, log(0.15)]\n",
    "- B) Compute option prices at each time-step for all paths\n",
    "    - two options: ATM calls and puts;\n",
    "- C) Split into train-test sets with 400K and 100K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BS_d1(S, dt, r, sigma, strike):\n",
    "    return (np.log(S/strike) + (r+sigma**2/2)*dt) / (sigma*np.sqrt(dt))\n",
    "\n",
    "# Style : +1 for call, -1 for put\n",
    "def BlackScholes_price(S, T, r, sigma, strike, style, t=0):\n",
    "    dt = T-t\n",
    "    Phi = stats.norm(loc=0, scale=1).cdf\n",
    "    d1 = BS_d1(S, dt, r, sigma, strike)\n",
    "    d2 = d1 - sigma*np.sqrt(dt)\n",
    "    return style*S*Phi(style*d1) - style*strike*np.exp(-r*dt)*Phi(style*d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters - MJD\n",
    "# nu, sigma and lambda_ are annual basis\n",
    "nu, sigma, lambda_, gamma, delta = [0.111093, 0.132288, 0.25, -0.10, 0.10]\n",
    "r                     = 0.03       # risk-free rate\n",
    "S_0                   = 100        # Initial stock price\n",
    "strike                = 100        # Strike of put option to price\n",
    "T                     = 1          # Time-to-maturity of put option\n",
    "n_sims                = 500000     # Total number of paths to simulate\n",
    "n_timesteps_daily     = int(T*252) # Daily\n",
    "n_timesteps_month     = int(T*12)  # month\n",
    "n_timesteps_quarterly = int(T*4)   # Quarterly\n",
    "\n",
    "# Parameters - IV dynamics\n",
    "kappa_IV, theta_IV, sigma_IV = [0.15, np.log(0.15), 0.06]\n",
    "IV_0                   = np.exp(theta_IV)\n",
    "rho                    = -0.6 # correlation term\n",
    "\n",
    "# A) Simulate daily MJD-AR(1) dynamics\n",
    "h                      = T / n_timesteps_daily  # step-size\n",
    "Price_mat_daily        = np.zeros((n_timesteps_daily+1, n_sims))\n",
    "Price_mat_daily[0,:]   = S_0\n",
    "log_IV_mat             = np.zeros((n_timesteps_daily+1, n_sims))\n",
    "log_IV_mat[0,:]        = np.log(IV_0)\n",
    "\n",
    "# Periodic parameters rescaling\n",
    "nu_per                 = nu*h\n",
    "sig_per                = sigma*np.sqrt(h)\n",
    "jumpInt_per            = lambda_ * h      \n",
    "kappa                  = np.exp(gamma + delta*delta/2) - 1 \n",
    "#a                      = nu_per - jumpInt_per*(np.exp(gamma + delta*delta/2) - 1) - 0.5*sig_per*sig_per\n",
    "a                      = nu_per - jumpInt_per*kappa - 0.5*sig_per*sig_per\n",
    "\n",
    "# 1) Simulate log-returns and IV \n",
    "for i in range(n_sims):\n",
    "    \n",
    "    # 1.1) Simulate all log-returns for the ith path \n",
    "    Z_0     = np.random.randn(n_timesteps_daily)\n",
    "    nbJumps = np.random.poisson(jumpInt_per, size=n_timesteps_daily)\n",
    "    Z       = a + gamma * nbJumps + np.sqrt(sig_per*sig_per + delta*delta * nbJumps)*Z_0\n",
    "    Price_mat_daily[1:,i] = S_0*np.exp(np.cumsum(Z))\n",
    "                        \n",
    "    # 1.2) Simulate implied volatilities from the log-AR(1) \n",
    "    for j in range(n_timesteps_daily):\n",
    "        Z_1 = np.random.randn(1)        \n",
    "        if(rho !=0):\n",
    "            log_IV_mat[j+1,i] = log_IV_mat[j,i] + kappa_IV*(theta_IV - log_IV_mat[j,i]) + sigma_IV*(rho*Z_0[j] + np.sqrt(1-rho**2)*Z_1)\n",
    "        else:\n",
    "            log_IV_mat[j+1,i] = log_IV_mat[j,i] + kappa_IV*(theta_IV - log_IV_mat[j,i]) + sigma_IV*Z_1\n",
    "            \n",
    "IV_mat     = np.exp(log_IV_mat)\n",
    "log_IV_mat = []\n",
    "\n",
    "# B) month time-steps\n",
    "idx             = np.arange(0, 253, 21)  #[0,21,...,252]\n",
    "Price_mat_month = Price_mat_daily[idx,:]\n",
    "IV_mat_month    = IV_mat[idx,:]\n",
    "\n",
    "# C) Quarterly time-steps\n",
    "idx             = np.arange(0, 253, 63)\n",
    "Price_mat_quart = Price_mat_daily[idx,:]\n",
    "IV_mat_quart    = IV_mat[idx,:]\n",
    "\n",
    "# D) Price month and quarterly ATM call and put\n",
    "Opts_month        = np.zeros((Price_mat_month.shape[0], Price_mat_month.shape[1], 2))\n",
    "Opts_month[:,:,0] = BlackScholes_price(Price_mat_month, 1/12, r, IV_mat_month, Price_mat_month, 1)\n",
    "Opts_month[:,:,1] = BlackScholes_price(Price_mat_month, 1/12, r, IV_mat_month, Price_mat_month, -1)\n",
    "Opts_month_train = Opts_month[:,0:400000,:]\n",
    "Opts_month_test  = Opts_month[:,400000:,:]\n",
    "\n",
    "Opts_quart        = np.zeros((Price_mat_quart.shape[0], Price_mat_quart.shape[1], 2))\n",
    "Opts_quart[:,:,0] = BlackScholes_price(Price_mat_quart, 3/12, r, IV_mat_quart, Price_mat_quart, 1)\n",
    "Opts_quart[:,:,1] = BlackScholes_price(Price_mat_quart, 3/12, r, IV_mat_quart, Price_mat_quart, -1)\n",
    "Opts_quart_train  = Opts_quart[:,0:400000,:]\n",
    "Opts_quart_test   = Opts_quart[:,400000:,:]\n",
    "\n",
    "# E) Split into train-test sets\n",
    "# E.1) Daily underlying: [S_t]\n",
    "train_stock_daily_input        = np.zeros((n_timesteps_daily+1, 400000,1))\n",
    "test_stock_daily_input         = np.zeros((n_timesteps_daily+1, 100000,1))\n",
    "train_stock_daily_input[:,:,0] = Price_mat_daily[:,0:400000]  \n",
    "test_stock_daily_input[:,:,0]  = Price_mat_daily[:,400000:]\n",
    "\n",
    "# E.2) month underlying [S_t]\n",
    "train_stock_month_input        = np.zeros((n_timesteps_month+1, 400000,1))\n",
    "test_stock_month_input         = np.zeros((n_timesteps_month+1, 100000,1))\n",
    "train_stock_month_input[:,:,0] = Price_mat_month[:,0:400000]  \n",
    "test_stock_month_input[:,:,0]  = Price_mat_month[:,400000:]\n",
    "\n",
    "# E.3) month ATM calls and puts [S_t, IV_t]\n",
    "train_opts_month_input         = np.zeros((n_timesteps_month+1, 400000,2))\n",
    "test_opts_month_input          = np.zeros((n_timesteps_month+1, 100000,2))\n",
    "train_opts_month_input[:,:,0]  = Price_mat_month[:,0:400000]  \n",
    "test_opts_month_input[:,:,0]   = Price_mat_month[:,400000:]\n",
    "train_opts_month_input[:,:,1]  = IV_mat_month[:,0:400000]\n",
    "test_opts_month_input[:,:,1]   = IV_mat_month[:,400000:]\n",
    "\n",
    "# E.4) Quarterly ATM calls and puts [S_t, IV_t]\n",
    "train_opts_quart_input         = np.zeros((n_timesteps_quarterly+1, 400000,2))\n",
    "test_opts_quart_input          = np.zeros((n_timesteps_quarterly+1, 100000,2))\n",
    "train_opts_quart_input[:,:,0]  = Price_mat_quart[:,0:400000]  \n",
    "test_opts_quart_input[:,:,0]   = Price_mat_quart[:,400000:]\n",
    "train_opts_quart_input[:,:,1]  = IV_mat_quart[:,0:400000]\n",
    "test_opts_quart_input[:,:,1]   = IV_mat_quart[:,400000:]\n",
    "\n",
    "# F) Preprocessing of stock prices {log(S_n/K)}\n",
    "prepro_stock = \"Log-moneyness\"\n",
    "if(prepro_stock == \"Log-moneyness\"):\n",
    "    train_stock_daily_input = np.log(train_stock_daily_input/strike)\n",
    "    test_stock_daily_input  = np.log(test_stock_daily_input/strike)\n",
    "    \n",
    "    train_stock_month_input = np.log(train_stock_month_input/strike)\n",
    "    test_stock_month_input  = np.log(test_stock_month_input/strike)    \n",
    "    \n",
    "    train_opts_month_input[:,:,0] = np.log(train_opts_month_input[:,:,0]/strike)\n",
    "    test_opts_month_input[:,:,0]  = np.log(test_opts_month_input[:,:,0]/strike)\n",
    "    \n",
    "    train_opts_quart_input[:,:,0] = np.log(train_opts_quart_input[:,:,0]/strike)\n",
    "    test_opts_quart_input[:,:,0]  = np.log(test_opts_quart_input[:,:,0]/strike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size     = 1000   # batch size\n",
    "epochs         = 50     # number of epochs\n",
    "nbs_layers     = 2      # number of LSTM cells\n",
    "nbs_units      = 24     # neurons per layer  \n",
    "alpha          = 0.95   # confidence level of the CVaR risk measure\n",
    "lr             = 0.01/6 # learning rate hyperparameter of Adam\n",
    "loss_type      = 'CVaR' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Tensor of discount factors\n",
    "- disc_mat: (n_timesteps+1 x n_sims x 1) tensor of cumulative discount rates (discount from t to 0), i.e. $\\exp(-rh*n)$ \n",
    "    - Will be split into disc_mat_train and disc_mat_test for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily tensors\n",
    "disc_mat_daily              = np.zeros((n_timesteps_daily+1, 500000, 1))\n",
    "disc_train_daily            = np.zeros((n_timesteps_daily+1, 400000, 1))\n",
    "disc_test_daily             = np.zeros((n_timesteps_daily+1, 100000, 1))\n",
    "discount_vect_daily         = np.ones(disc_mat_daily.shape[0])   \n",
    "h                           = T / n_timesteps_daily\n",
    "discount_vect_daily[1:]     = np.exp(-r*h)              # [1,exp(-rh), exp(-rh),....,exp(-rh)]\n",
    "discount_vect_daily         = np.cumprod(discount_vect_daily) # [1,exp(-rh), exp(-r2h),....,exp(-rNh)]\n",
    "disc_mat_daily              = np.reshape(np.repeat(discount_vect_daily, 500000), (n_timesteps_daily+1, 500000,1))\n",
    "disc_train_daily            = disc_mat_daily[:,0:400000,:]\n",
    "disc_test_daily             = disc_mat_daily[:,400000::,:]\n",
    "disc_batch_daily            = disc_mat_daily[:,0:batch_size,:]  # for convenience when only batch-size is needed\n",
    "disc_mat_daily              = []\n",
    "\n",
    "# month tensors\n",
    "disc_mat_month              = np.zeros((n_timesteps_month+1, 500000, 1))\n",
    "disc_train_month            = np.zeros((n_timesteps_month+1, 400000, 1))\n",
    "disc_test_month             = np.zeros((n_timesteps_month+1, 100000, 1))\n",
    "discount_vect_month         = np.ones(disc_mat_month.shape[0])   \n",
    "h                           = T / n_timesteps_month\n",
    "discount_vect_month[1:]     = np.exp(-r*h)              # [1,exp(-rh), exp(-rh),....,exp(-rh)]\n",
    "discount_vect_month         = np.cumprod(discount_vect_month) # [1,exp(-rh), exp(-r2h),....,exp(-rNh)]\n",
    "disc_mat_month              = np.reshape(np.repeat(discount_vect_month, 500000), (n_timesteps_month+1, 500000,1))\n",
    "disc_train_month            = disc_mat_month[:,0:40000,:]\n",
    "disc_test_month             = disc_mat_month[:,400000::,:]\n",
    "disc_batch_month            = disc_mat_month[:,0:batch_size,:]  # for convenience when only batch-size is needed\n",
    "disc_mat_month              = []\n",
    "\n",
    "# Quarterly tensors\n",
    "disc_mat_quart              = np.zeros((n_timesteps_quarterly+1, 500000, 1))\n",
    "disc_train_quart            = np.zeros((n_timesteps_quarterly+1, 40000, 1))\n",
    "disc_test_quart             = np.zeros((n_timesteps_quarterly+1, 100000, 1))\n",
    "discount_vect_quart         = np.ones(disc_mat_quart.shape[0])   \n",
    "h                           = T / n_timesteps_quarterly\n",
    "discount_vect_quart[1:]     = np.exp(-r*h)              # [1,exp(-rh), exp(-rh),....,exp(-rh)]\n",
    "discount_vect_quart         = np.cumprod(discount_vect_quart) # [1,exp(-rh), exp(-r2h),....,exp(-rNh)]\n",
    "disc_mat_quart              = np.reshape(np.repeat(discount_vect_quart, 500000), (n_timesteps_quarterly+1, 500000,1))\n",
    "disc_train_quart            = disc_mat_quart[:,0:400000,:]\n",
    "disc_test_quart             = disc_mat_quart[:,400000::,:]\n",
    "disc_batch_quart            = disc_mat_quart[:,0:batch_size,:]  # for convenience when only batch-size is needed\n",
    "disc_mat_quart              = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Function to compute the measured risk exposure given a sample of paths and hedging decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------------------------#\n",
    "#---------------      Functions to evaluate the measured risk exposure       ---------------------#\n",
    "#-------------------------------------------------------------------------------------------------#\n",
    "\"\"\" \n",
    "Input:\n",
    "- deltas             : (time step x nbs of paths) \n",
    "- paths              : (time step x nbs of paths)  \n",
    "- disc_paths         : (time step x nbs of paths x 1)\n",
    "- alpha              : for the CVaR computation\n",
    "- position_type      : {Long, Short}\n",
    "- hedging_instruments: {\"Stock\", \"ATM call and put\"}\n",
    "- prepro_stock       : {Log, Log-moneyness, Nothing} - what transformation was used for stock prices\n",
    "- option_prices      : Prices of options used as hedging instruments (not used if trading stock)\n",
    "\"\"\"\n",
    "#-------------------------------------------------------------------------------------------------#\n",
    "def measured_risk_exposures(deltas, paths, disc_paths, strike, position_type, hedging_instruments,\n",
    "                            prepro_stock, option_prices = -999999999999):\n",
    "    \n",
    "    # 1) Store the number of hedging instruments\n",
    "    nbs_assets = deltas.shape[2] \n",
    "    \n",
    "    # 2) Store prices of the underlying unormalized\n",
    "    underlying_unorm_prices = inverse_processing(paths[:,:,0], prepro_stock, strike)\n",
    "\n",
    "    # 3) Store the unormalized hedging instrument prices\n",
    "    if(hedging_instruments == \"Stock\"):\n",
    "        unorm_hedging_inst_price_b = np.expand_dims(inverse_processing(paths[0:-1,:,0], prepro_stock, strike),axis=2)\n",
    "        unorm_hedging_inst_price_e = np.expand_dims(inverse_processing(paths[1:,:,0], prepro_stock, strike),axis=2)\n",
    "\n",
    "    elif(hedging_instruments == \"ATM call and put\"):\n",
    "        unorm_hedging_inst_price_b = option_prices[0:-1,:,:]\n",
    "        unorm_hedging_inst_price_e = payoff_liquid_inst_func(underlying_unorm_prices)\n",
    "\n",
    "  \n",
    "    # 4) Store the unormalized hedging instrument prices discounted at time \"0\"    \n",
    "    unorm_discount_hedging_inst_price_b = unorm_hedging_inst_price_b*disc_paths[0:-1,:,:]\n",
    "    unorm_discount_hedging_inst_price_e = unorm_hedging_inst_price_e*disc_paths[1:,:,:]\n",
    "    inc_disc_ret                        = unorm_discount_hedging_inst_price_e - unorm_discount_hedging_inst_price_b\n",
    "        \n",
    "    # 5) Option payoff of vanilla ATM put\n",
    "    option_payoff  = np.maximum(strike - underlying_unorm_prices[-1,:],0) \n",
    "    \n",
    "    # 6) Compute the hedging error\n",
    "    cumulative_factor = np.reciprocal(disc_paths[-1,:,0]) \n",
    "    disc_hedging_gain = np.sum(np.sum(deltas*inc_disc_ret, axis = 0), axis = 1) # as of T\n",
    "    \n",
    "    if(position_type == 'Short'):\n",
    "        hedging_err = option_payoff - cumulative_factor*disc_hedging_gain\n",
    "    elif(position_type == 'Long'):\n",
    "        hedging_err = -option_payoff - cumulative_factor*disc_hedging_gain\n",
    "    \n",
    "    # 7) Empirical CVaR at level alpha\n",
    "    loss = np.mean(np.sort(hedging_err)[int(alpha*hedging_err.shape[0]):])\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "def payoff_liquid_inst_func(underlying_unorm_prices): \n",
    "    payoff_call = np.expand_dims(np.maximum(underlying_unorm_prices[1:,:] - underlying_unorm_prices[0:-1,:], 0), axis=2)\n",
    "    payoff_put = np.expand_dims(np.maximum(underlying_unorm_prices[0:-1,:] - underlying_unorm_prices[1:,:], 0), axis=2)\n",
    "\n",
    "    # Compilation\n",
    "    payoff = np.concatenate([payoff_call, payoff_put], axis=2)\n",
    "        \n",
    "    return payoff\n",
    "\n",
    "# De-normalize the stock price process\n",
    "def inverse_processing(paths, prepro_stock, strike = -9999999):\n",
    "    if(prepro_stock == \"Log\"):\n",
    "        paths = np.exp(paths)\n",
    "    elif(prepro_stock == \"Log-moneyness\"):\n",
    "        paths = strike*np.exp(paths)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Training of the short neural network and computation of the short measured risk exposure $$\\epsilon^{(S)}(0) = \\underset{\\delta \\in \\Pi}{\\min} \\, \\rho \\left(\\Phi(S_{N},Z_{N}) - B_{N}G_{N}^{\\delta}\\right).$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.A) With underlying stock - daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Start training---\n",
      "Time elapsed: 0:01:55.164542\n",
      "Epoch 1, CVaR - Train: 10.540\n",
      "Time elapsed: 0:03:34.698418\n",
      "Epoch 2, CVaR - Train: 9.882\n",
      "Time elapsed: 0:05:13.996033\n",
      "Epoch 3, CVaR - Train: 9.819\n",
      "Time elapsed: 0:06:52.674893\n",
      "Epoch 4, CVaR - Train: 9.746\n",
      "Time elapsed: 0:08:31.468835\n",
      "Epoch 5, CVaR - Train: 9.721\n",
      "Time elapsed: 0:10:09.170208\n",
      "Epoch 6, CVaR - Train: 9.669\n",
      "Time elapsed: 0:11:44.413670\n",
      "Epoch 7, CVaR - Train: 9.671\n",
      "Time elapsed: 0:13:22.094851\n",
      "Epoch 8, CVaR - Train: 9.591\n",
      "Time elapsed: 0:14:57.252480\n",
      "Epoch 9, CVaR - Train: 9.639\n",
      "Time elapsed: 0:16:32.511121\n",
      "Epoch 10, CVaR - Train: 9.607\n",
      "Time elapsed: 0:18:10.283334\n",
      "Epoch 11, CVaR - Train: 9.543\n",
      "Time elapsed: 0:19:48.029540\n",
      "Epoch 12, CVaR - Train: 9.472\n",
      "Time elapsed: 0:21:23.088127\n",
      "Epoch 13, CVaR - Train: 9.498\n",
      "Time elapsed: 0:22:58.238753\n",
      "Epoch 14, CVaR - Train: 9.525\n",
      "Time elapsed: 0:24:36.086983\n",
      "Epoch 15, CVaR - Train: 9.455\n",
      "Time elapsed: 0:26:11.363618\n",
      "Epoch 16, CVaR - Train: 9.457\n",
      "Time elapsed: 0:27:49.198855\n",
      "Epoch 17, CVaR - Train: 9.399\n",
      "Time elapsed: 0:29:27.059087\n",
      "Epoch 18, CVaR - Train: 9.390\n",
      "Time elapsed: 0:31:04.610249\n",
      "Epoch 19, CVaR - Train: 9.384\n",
      "Time elapsed: 0:32:39.886895\n",
      "Epoch 20, CVaR - Train: 9.422\n",
      "Time elapsed: 0:34:14.984499\n",
      "Epoch 21, CVaR - Train: 9.408\n",
      "Time elapsed: 0:35:50.061089\n",
      "Epoch 22, CVaR - Train: 9.492\n",
      "Time elapsed: 0:37:25.089689\n",
      "Epoch 23, CVaR - Train: 9.385\n",
      "Time elapsed: 0:39:00.469357\n",
      "Epoch 24, CVaR - Train: 9.424\n",
      "Time elapsed: 0:40:38.795696\n",
      "Epoch 25, CVaR - Train: 9.347\n",
      "Time elapsed: 0:42:16.979001\n",
      "Epoch 26, CVaR - Train: 9.301\n",
      "Time elapsed: 0:43:52.413683\n",
      "Epoch 27, CVaR - Train: 9.402\n",
      "Time elapsed: 0:45:28.176429\n",
      "Epoch 28, CVaR - Train: 9.370\n",
      "Time elapsed: 0:47:03.790161\n",
      "Epoch 29, CVaR - Train: 9.513\n",
      "Time elapsed: 0:48:39.458895\n",
      "Epoch 30, CVaR - Train: 9.450\n",
      "Time elapsed: 0:50:14.975595\n",
      "Epoch 31, CVaR - Train: 9.336\n",
      "Time elapsed: 0:51:50.215232\n",
      "Epoch 32, CVaR - Train: 9.345\n",
      "Time elapsed: 0:53:28.603584\n",
      "Epoch 33, CVaR - Train: 9.244\n",
      "Time elapsed: 0:55:06.681867\n",
      "Epoch 34, CVaR - Train: 9.175\n",
      "Time elapsed: 0:56:42.367594\n",
      "Epoch 35, CVaR - Train: 9.287\n",
      "Time elapsed: 0:58:20.368012\n",
      "Epoch 36, CVaR - Train: 9.133\n",
      "Time elapsed: 0:59:56.088756\n",
      "Epoch 37, CVaR - Train: 9.394\n",
      "Time elapsed: 1:01:31.646468\n",
      "Epoch 38, CVaR - Train: 9.337\n",
      "Time elapsed: 1:03:07.033138\n",
      "Epoch 39, CVaR - Train: 9.425\n",
      "Time elapsed: 1:04:42.629856\n",
      "Epoch 40, CVaR - Train: 9.351\n",
      "Time elapsed: 1:06:17.931496\n",
      "Epoch 41, CVaR - Train: 9.271\n",
      "Time elapsed: 1:07:53.624236\n",
      "Epoch 42, CVaR - Train: 9.308\n",
      "Time elapsed: 1:09:29.196949\n",
      "Epoch 43, CVaR - Train: 9.296\n",
      "Time elapsed: 1:11:04.724651\n",
      "Epoch 44, CVaR - Train: 9.302\n",
      "Time elapsed: 1:12:40.349376\n",
      "Epoch 45, CVaR - Train: 9.818\n",
      "Time elapsed: 1:14:15.782067\n",
      "Epoch 46, CVaR - Train: 9.294\n",
      "Time elapsed: 1:15:51.347768\n",
      "Epoch 47, CVaR - Train: 9.275\n",
      "Time elapsed: 1:17:27.114536\n",
      "Epoch 48, CVaR - Train: 9.278\n",
      "Time elapsed: 1:19:02.713243\n",
      "Epoch 49, CVaR - Train: 9.304\n",
      "Time elapsed: 1:20:39.105143\n",
      "Epoch 50, CVaR - Train: 9.276\n",
      "---Finished training results---\n",
      "Time elapsed: 1:20:39.106143\n",
      "---Training end---\n",
      "INFO:tensorflow:Restoring parameters from /Users/alexa/Github files/ERP with multi hedging instruments/Models/Daily_stock_short/models.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Normalization \n",
    "nbs_assets                = 1\n",
    "hedging_instruments       = \"Stock\"\n",
    "model_name                = 'Daily_stock_short'\n",
    "position_type             = \"Short\"\n",
    "\n",
    "LSTM_underlying = DeepAgent(train_stock_daily_input.shape[0], batch_size, train_stock_daily_input.shape[2], \n",
    "        loss_type, nbs_assets, position_type, nbs_layers, nbs_units, lr, prepro_stock, \n",
    "        hedging_instruments, alpha, name = model_name)\n",
    "\n",
    "# Start training \n",
    "start = dt.datetime.now()\n",
    "\n",
    "print('---Start training---')\n",
    "with tf.Session() as sess:           \n",
    "    loss_epoch = LSTM_underlying.training(train_stock_daily_input, disc_batch_daily, sess, epochs)\n",
    "    print('---Training end---')\n",
    "\n",
    "model_predict = DeepAgent(test_stock_daily_input.shape[0], batch_size, test_stock_daily_input.shape[2], \n",
    "        loss_type, nbs_assets, position_type, nbs_layers, nbs_units, lr, prepro_stock, \n",
    "        hedging_instruments, alpha, name = model_name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Load the saved model\n",
    "    model_predict.restore(sess, r\"/Users/alexa/Github files/ERP with multi hedging instruments/Models/%s/models.ckpt\" % model_name)\n",
    "    deltas = model_predict.predict(test_stock_daily_input, disc_test_daily, sess, loss_type)\n",
    "    CVaR_95_short_test_stock_daily = measured_risk_exposures(deltas, test_stock_daily_input, \n",
    "                            disc_test_daily, strike, position_type, hedging_instruments, prepro_stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.B) With underlying stock - month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Start training---\n",
      "Time elapsed: 0:00:05.962354\n",
      "Epoch 1, CVaR - Train: 11.347\n",
      "Time elapsed: 0:00:11.311752\n",
      "Epoch 2, CVaR - Train: 10.485\n",
      "Time elapsed: 0:00:16.645973\n",
      "Epoch 3, CVaR - Train: 10.381\n",
      "Time elapsed: 0:00:21.970424\n",
      "Epoch 4, CVaR - Train: 10.300\n",
      "Time elapsed: 0:00:27.294624\n",
      "Epoch 5, CVaR - Train: 10.228\n",
      "Time elapsed: 0:00:32.611842\n",
      "Epoch 6, CVaR - Train: 10.189\n",
      "Time elapsed: 0:00:37.939200\n",
      "Epoch 7, CVaR - Train: 10.143\n",
      "Time elapsed: 0:00:43.262583\n",
      "Epoch 8, CVaR - Train: 10.112\n",
      "Time elapsed: 0:00:48.575616\n",
      "Epoch 9, CVaR - Train: 10.085\n",
      "Time elapsed: 0:00:53.880968\n",
      "Epoch 10, CVaR - Train: 10.076\n",
      "Time elapsed: 0:00:59.213179\n",
      "Epoch 11, CVaR - Train: 10.037\n",
      "Time elapsed: 0:01:04.628481\n",
      "Epoch 12, CVaR - Train: 10.017\n",
      "Time elapsed: 0:01:10.015830\n",
      "Epoch 13, CVaR - Train: 10.016\n",
      "Time elapsed: 0:01:15.368737\n",
      "Epoch 14, CVaR - Train: 10.005\n",
      "Time elapsed: 0:01:20.754933\n",
      "Epoch 15, CVaR - Train: 9.990\n",
      "Time elapsed: 0:01:26.107174\n",
      "Epoch 16, CVaR - Train: 9.981\n",
      "Time elapsed: 0:01:31.477176\n",
      "Epoch 17, CVaR - Train: 9.940\n",
      "Time elapsed: 0:01:36.698121\n",
      "Epoch 18, CVaR - Train: 9.949\n",
      "Time elapsed: 0:01:41.904142\n",
      "Epoch 19, CVaR - Train: 9.943\n",
      "Time elapsed: 0:01:47.260062\n",
      "Epoch 20, CVaR - Train: 9.926\n",
      "Time elapsed: 0:01:52.631207\n",
      "Epoch 21, CVaR - Train: 9.909\n",
      "Time elapsed: 0:01:57.839107\n",
      "Epoch 22, CVaR - Train: 9.916\n",
      "Time elapsed: 0:02:03.195320\n",
      "Epoch 23, CVaR - Train: 9.872\n",
      "Time elapsed: 0:02:08.409104\n",
      "Epoch 24, CVaR - Train: 9.894\n",
      "Time elapsed: 0:02:13.617936\n",
      "Epoch 25, CVaR - Train: 9.884\n",
      "Time elapsed: 0:02:18.975607\n",
      "Epoch 26, CVaR - Train: 9.836\n",
      "Time elapsed: 0:02:24.172319\n",
      "Epoch 27, CVaR - Train: 9.865\n",
      "Time elapsed: 0:02:29.542069\n",
      "Epoch 28, CVaR - Train: 9.834\n",
      "Time elapsed: 0:02:34.783396\n",
      "Epoch 29, CVaR - Train: 9.847\n",
      "Time elapsed: 0:02:40.150289\n",
      "Epoch 30, CVaR - Train: 9.803\n",
      "Time elapsed: 0:02:45.319736\n",
      "Epoch 31, CVaR - Train: 9.822\n",
      "Time elapsed: 0:02:50.477908\n",
      "Epoch 32, CVaR - Train: 9.822\n",
      "Time elapsed: 0:02:55.800654\n",
      "Epoch 33, CVaR - Train: 9.792\n",
      "Time elapsed: 0:03:00.967827\n",
      "Epoch 34, CVaR - Train: 9.815\n",
      "Time elapsed: 0:03:06.132195\n",
      "Epoch 35, CVaR - Train: 9.796\n",
      "Time elapsed: 0:03:11.450650\n",
      "Epoch 36, CVaR - Train: 9.780\n",
      "Time elapsed: 0:03:16.781862\n",
      "Epoch 37, CVaR - Train: 9.755\n",
      "Time elapsed: 0:03:21.955027\n",
      "Epoch 38, CVaR - Train: 9.763\n",
      "Time elapsed: 0:03:27.273246\n",
      "Epoch 39, CVaR - Train: 9.750\n",
      "Time elapsed: 0:03:32.420415\n",
      "Epoch 40, CVaR - Train: 9.767\n",
      "Time elapsed: 0:03:37.595707\n",
      "Epoch 41, CVaR - Train: 9.777\n",
      "Time elapsed: 0:03:42.748962\n",
      "Epoch 42, CVaR - Train: 9.758\n",
      "Time elapsed: 0:03:48.058167\n",
      "Epoch 43, CVaR - Train: 9.739\n",
      "Time elapsed: 0:03:53.213338\n",
      "Epoch 44, CVaR - Train: 9.746\n",
      "Time elapsed: 0:03:58.528980\n",
      "Epoch 45, CVaR - Train: 9.706\n",
      "Time elapsed: 0:04:03.853324\n",
      "Epoch 46, CVaR - Train: 9.703\n",
      "Time elapsed: 0:04:09.017498\n",
      "Epoch 47, CVaR - Train: 9.707\n",
      "Time elapsed: 0:04:14.335821\n",
      "Epoch 48, CVaR - Train: 9.688\n",
      "Time elapsed: 0:04:19.662916\n",
      "Epoch 49, CVaR - Train: 9.685\n",
      "Time elapsed: 0:04:24.824078\n",
      "Epoch 50, CVaR - Train: 9.699\n",
      "---Finished training results---\n",
      "Time elapsed: 0:04:24.825079\n",
      "---Training end---\n",
      "INFO:tensorflow:Restoring parameters from /Users/alexa/Github files/ERP with multi hedging instruments/Models/Month_stock_short/models.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Normalization \n",
    "nbs_assets                = 1\n",
    "hedging_instruments       = \"Stock\"\n",
    "model_name                = 'Month_stock_short'\n",
    "position_type             = \"Short\"\n",
    "\n",
    "LSTM_underlying = DeepAgent(train_stock_month_input.shape[0], batch_size, train_stock_month_input.shape[2], \n",
    "        loss_type, nbs_assets, position_type, nbs_layers, nbs_units, lr, prepro_stock, \n",
    "        hedging_instruments, alpha, name = model_name)\n",
    "\n",
    "# Start training \n",
    "start = dt.datetime.now()\n",
    "\n",
    "print('---Start training---')\n",
    "with tf.Session() as sess:           \n",
    "    loss_epoch = LSTM_underlying.training(train_stock_month_input, disc_batch_month, sess, epochs)\n",
    "    print('---Training end---')\n",
    "        \n",
    "model_predict = DeepAgent(test_stock_month_input.shape[0], batch_size, test_stock_month_input.shape[2], \n",
    "        loss_type, nbs_assets, position_type, nbs_layers, nbs_units, lr, prepro_stock, \n",
    "        hedging_instruments, alpha, name = model_name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model_predict.restore(sess, r\"/Users/alexa/Github files/ERP with multi hedging instruments/Models/%s/models.ckpt\" % model_name)\n",
    "    deltas = model_predict.predict(test_stock_month_input, disc_test_month, sess, loss_type)\n",
    "    CVaR_95_short_test_stock_month = measured_risk_exposures(deltas, test_stock_month_input, \n",
    "                            disc_test_month, strike, position_type, hedging_instruments, prepro_stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.C) With two opts - month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Start training---\n",
      "Time elapsed: 0:00:07.065906\n",
      "Epoch 1, CVaR - Train: 9.660\n",
      "Time elapsed: 0:00:13.358501\n",
      "Epoch 2, CVaR - Train: 8.207\n",
      "Time elapsed: 0:00:19.642262\n",
      "Epoch 3, CVaR - Train: 8.111\n",
      "Time elapsed: 0:00:25.913687\n",
      "Epoch 4, CVaR - Train: 8.009\n",
      "Time elapsed: 0:00:32.191140\n",
      "Epoch 5, CVaR - Train: 7.919\n",
      "Time elapsed: 0:00:38.471867\n",
      "Epoch 6, CVaR - Train: 7.877\n",
      "Time elapsed: 0:00:44.743694\n",
      "Epoch 7, CVaR - Train: 7.845\n",
      "Time elapsed: 0:00:51.050126\n",
      "Epoch 8, CVaR - Train: 7.796\n",
      "Time elapsed: 0:00:57.314576\n",
      "Epoch 9, CVaR - Train: 7.767\n",
      "Time elapsed: 0:01:03.613133\n",
      "Epoch 10, CVaR - Train: 7.764\n",
      "Time elapsed: 0:01:09.906981\n",
      "Epoch 11, CVaR - Train: 7.752\n",
      "Time elapsed: 0:01:16.192742\n",
      "Epoch 12, CVaR - Train: 7.726\n",
      "Time elapsed: 0:01:22.470566\n",
      "Epoch 13, CVaR - Train: 7.699\n",
      "Time elapsed: 0:01:28.772493\n",
      "Epoch 14, CVaR - Train: 7.679\n",
      "Time elapsed: 0:01:34.899924\n",
      "Epoch 15, CVaR - Train: 7.679\n",
      "Time elapsed: 0:01:41.203749\n",
      "Epoch 16, CVaR - Train: 7.645\n",
      "Time elapsed: 0:01:47.464300\n",
      "Epoch 17, CVaR - Train: 7.631\n",
      "Time elapsed: 0:01:53.748118\n",
      "Epoch 18, CVaR - Train: 7.610\n",
      "Time elapsed: 0:01:59.869286\n",
      "Epoch 19, CVaR - Train: 7.627\n",
      "Time elapsed: 0:02:06.148942\n",
      "Epoch 20, CVaR - Train: 7.575\n",
      "Time elapsed: 0:02:12.430483\n",
      "Epoch 21, CVaR - Train: 7.569\n",
      "Time elapsed: 0:02:18.707925\n",
      "Epoch 22, CVaR - Train: 7.554\n",
      "Time elapsed: 0:02:24.982648\n",
      "Epoch 23, CVaR - Train: 7.531\n",
      "Time elapsed: 0:02:31.266152\n",
      "Epoch 24, CVaR - Train: 7.517\n",
      "Time elapsed: 0:02:37.575745\n",
      "Epoch 25, CVaR - Train: 7.501\n",
      "Time elapsed: 0:02:43.871176\n",
      "Epoch 26, CVaR - Train: 7.455\n",
      "Time elapsed: 0:02:50.005569\n",
      "Epoch 27, CVaR - Train: 7.460\n",
      "Time elapsed: 0:02:56.297998\n",
      "Epoch 28, CVaR - Train: 7.418\n",
      "Time elapsed: 0:03:02.426749\n",
      "Epoch 29, CVaR - Train: 7.430\n",
      "Time elapsed: 0:03:08.716037\n",
      "Epoch 30, CVaR - Train: 7.378\n",
      "Time elapsed: 0:03:15.005520\n",
      "Epoch 31, CVaR - Train: 7.358\n",
      "Time elapsed: 0:03:21.110224\n",
      "Epoch 32, CVaR - Train: 7.408\n",
      "Time elapsed: 0:03:27.228921\n",
      "Epoch 33, CVaR - Train: 7.395\n",
      "Time elapsed: 0:03:33.348437\n",
      "Epoch 34, CVaR - Train: 7.446\n",
      "Time elapsed: 0:03:39.653008\n",
      "Epoch 35, CVaR - Train: 7.251\n",
      "Time elapsed: 0:03:45.772948\n",
      "Epoch 36, CVaR - Train: 7.488\n",
      "Time elapsed: 0:03:51.912769\n",
      "Epoch 37, CVaR - Train: 7.798\n",
      "Time elapsed: 0:03:58.048440\n",
      "Epoch 38, CVaR - Train: 7.398\n",
      "Time elapsed: 0:04:04.156037\n",
      "Epoch 39, CVaR - Train: 7.281\n",
      "Time elapsed: 0:04:10.280988\n",
      "Epoch 40, CVaR - Train: 7.316\n",
      "Time elapsed: 0:04:16.572008\n",
      "Epoch 41, CVaR - Train: 7.244\n",
      "Time elapsed: 0:04:22.694059\n",
      "Epoch 42, CVaR - Train: 7.286\n",
      "Time elapsed: 0:04:28.821798\n",
      "Epoch 43, CVaR - Train: 7.338\n",
      "Time elapsed: 0:04:35.107552\n",
      "Epoch 44, CVaR - Train: 7.221\n",
      "Time elapsed: 0:04:41.422987\n",
      "Epoch 45, CVaR - Train: 7.218\n",
      "Time elapsed: 0:04:47.717069\n",
      "Epoch 46, CVaR - Train: 7.144\n",
      "Time elapsed: 0:04:53.845466\n",
      "Epoch 47, CVaR - Train: 7.264\n",
      "Time elapsed: 0:04:59.961207\n",
      "Epoch 48, CVaR - Train: 7.197\n",
      "Time elapsed: 0:05:06.054580\n",
      "Epoch 49, CVaR - Train: 7.180\n",
      "Time elapsed: 0:05:12.168969\n",
      "Epoch 50, CVaR - Train: 7.340\n",
      "---Finished training results---\n",
      "Time elapsed: 0:05:12.168969\n",
      "---Training end---\n",
      "INFO:tensorflow:Restoring parameters from /Users/alexa/Github files/ERP with multi hedging instruments/Models/Month_opts_short/models.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Normalization \n",
    "nbs_assets                = 2\n",
    "hedging_instruments       = \"ATM call and put\"\n",
    "model_name                = 'Month_opts_short'\n",
    "position_type             = \"Short\"\n",
    "\n",
    "LSTM_underlying = DeepAgent(train_opts_month_input.shape[0], batch_size, train_opts_month_input.shape[2], \n",
    "        loss_type, nbs_assets, position_type, nbs_layers, nbs_units, lr, prepro_stock, \n",
    "        hedging_instruments, alpha, name = model_name)\n",
    "\n",
    "# Start training \n",
    "start = dt.datetime.now()\n",
    "\n",
    "print('---Start training---')\n",
    "with tf.Session() as sess:           \n",
    "    loss_epoch = LSTM_underlying.training(train_opts_month_input, disc_batch_month, sess, epochs,\n",
    "                                            Opts_month_train)\n",
    "    print('---Training end---')\n",
    "        \n",
    "model_predict = DeepAgent(test_opts_month_input.shape[0], batch_size, test_opts_month_input.shape[2], \n",
    "        loss_type, nbs_assets, position_type, nbs_layers, nbs_units, lr, prepro_stock, \n",
    "        hedging_instruments, alpha, name = model_name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Load the saved model\n",
    "    model_predict.restore(sess, r\"/Users/alexa/Github files/ERP with multi hedging instruments/Models/%s/models.ckpt\" % model_name)\n",
    "    deltas = model_predict.predict(test_opts_month_input, disc_test_month, sess, loss_type, Opts_month_test)\n",
    "    CVaR_95_short_test_opts_month = measured_risk_exposures(deltas, test_opts_month_input, \n",
    "                            disc_test_month, strike, position_type, hedging_instruments, prepro_stock, Opts_month_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.D) With two opts - quarterly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Start training---\n",
      "Time elapsed: 0:00:02.926702\n",
      "Epoch 1, CVaR - Train: 9.749\n",
      "Time elapsed: 0:00:05.569303\n",
      "Epoch 2, CVaR - Train: 7.779\n",
      "Time elapsed: 0:00:08.220551\n",
      "Epoch 3, CVaR - Train: 7.619\n",
      "Time elapsed: 0:00:10.879024\n",
      "Epoch 4, CVaR - Train: 7.550\n",
      "Time elapsed: 0:00:13.523908\n",
      "Epoch 5, CVaR - Train: 7.520\n",
      "Time elapsed: 0:00:16.175710\n",
      "Epoch 6, CVaR - Train: 7.479\n",
      "Time elapsed: 0:00:18.944340\n",
      "Epoch 7, CVaR - Train: 7.475\n",
      "Time elapsed: 0:00:21.600944\n",
      "Epoch 8, CVaR - Train: 7.447\n",
      "Time elapsed: 0:00:24.252685\n",
      "Epoch 9, CVaR - Train: 7.413\n",
      "Time elapsed: 0:00:26.900368\n",
      "Epoch 10, CVaR - Train: 7.398\n",
      "Time elapsed: 0:00:29.548428\n",
      "Epoch 11, CVaR - Train: 7.365\n",
      "Time elapsed: 0:00:32.196367\n",
      "Epoch 12, CVaR - Train: 7.356\n",
      "Time elapsed: 0:00:34.760376\n",
      "Epoch 13, CVaR - Train: 7.368\n",
      "Time elapsed: 0:00:37.418122\n",
      "Epoch 14, CVaR - Train: 7.350\n",
      "Time elapsed: 0:00:40.066465\n",
      "Epoch 15, CVaR - Train: 7.347\n",
      "Time elapsed: 0:00:42.703064\n",
      "Epoch 16, CVaR - Train: 7.338\n",
      "Time elapsed: 0:00:45.340781\n",
      "Epoch 17, CVaR - Train: 7.330\n",
      "Time elapsed: 0:00:47.995384\n",
      "Epoch 18, CVaR - Train: 7.321\n",
      "Time elapsed: 0:00:50.632983\n",
      "Epoch 19, CVaR - Train: 7.306\n",
      "Time elapsed: 0:00:53.272029\n",
      "Epoch 20, CVaR - Train: 7.293\n",
      "Time elapsed: 0:00:55.824609\n",
      "Epoch 21, CVaR - Train: 7.298\n",
      "Time elapsed: 0:00:58.375433\n",
      "Epoch 22, CVaR - Train: 7.295\n",
      "Time elapsed: 0:01:01.005298\n",
      "Epoch 23, CVaR - Train: 7.277\n",
      "Time elapsed: 0:01:03.652412\n",
      "Epoch 24, CVaR - Train: 7.275\n",
      "Time elapsed: 0:01:06.298165\n",
      "Epoch 25, CVaR - Train: 7.261\n",
      "Time elapsed: 0:01:08.931763\n",
      "Epoch 26, CVaR - Train: 7.260\n",
      "Time elapsed: 0:01:11.493345\n",
      "Epoch 27, CVaR - Train: 7.290\n",
      "Time elapsed: 0:01:14.050065\n",
      "Epoch 28, CVaR - Train: 7.263\n",
      "Time elapsed: 0:01:16.602644\n",
      "Epoch 29, CVaR - Train: 7.269\n",
      "Time elapsed: 0:01:19.241235\n",
      "Epoch 30, CVaR - Train: 7.259\n",
      "Time elapsed: 0:01:21.896847\n",
      "Epoch 31, CVaR - Train: 7.256\n",
      "Time elapsed: 0:01:24.539438\n",
      "Epoch 32, CVaR - Train: 7.239\n",
      "Time elapsed: 0:01:27.096575\n",
      "Epoch 33, CVaR - Train: 7.240\n",
      "Time elapsed: 0:01:29.645282\n",
      "Epoch 34, CVaR - Train: 7.243\n",
      "Time elapsed: 0:01:32.293884\n",
      "Epoch 35, CVaR - Train: 7.224\n",
      "Time elapsed: 0:01:34.848604\n",
      "Epoch 36, CVaR - Train: 7.231\n",
      "Time elapsed: 0:01:37.405583\n",
      "Epoch 37, CVaR - Train: 7.234\n",
      "Time elapsed: 0:01:40.052209\n",
      "Epoch 38, CVaR - Train: 7.203\n",
      "Time elapsed: 0:01:42.604931\n",
      "Epoch 39, CVaR - Train: 7.217\n",
      "Time elapsed: 0:01:45.156512\n",
      "Epoch 40, CVaR - Train: 7.229\n",
      "Time elapsed: 0:01:47.701884\n",
      "Epoch 41, CVaR - Train: 7.223\n",
      "Time elapsed: 0:01:50.344886\n",
      "Epoch 42, CVaR - Train: 7.195\n",
      "Time elapsed: 0:01:52.900466\n",
      "Epoch 43, CVaR - Train: 7.198\n",
      "Time elapsed: 0:01:55.540718\n",
      "Epoch 44, CVaR - Train: 7.194\n",
      "Time elapsed: 0:01:58.086655\n",
      "Epoch 45, CVaR - Train: 7.203\n",
      "Time elapsed: 0:02:00.720372\n",
      "Epoch 46, CVaR - Train: 7.176\n",
      "Time elapsed: 0:02:03.274382\n",
      "Epoch 47, CVaR - Train: 7.191\n",
      "Time elapsed: 0:02:05.827962\n",
      "Epoch 48, CVaR - Train: 7.192\n",
      "Time elapsed: 0:02:08.380067\n",
      "Epoch 49, CVaR - Train: 7.194\n",
      "Time elapsed: 0:02:10.935004\n",
      "Epoch 50, CVaR - Train: 7.181\n",
      "---Finished training results---\n",
      "Time elapsed: 0:02:10.935004\n",
      "---Training end---\n",
      "INFO:tensorflow:Restoring parameters from /Users/alexa/Github files/ERP with multi hedging instruments/Models/Quart_opts_short/models.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Normalization \n",
    "nbs_assets                = 2\n",
    "hedging_instruments       = \"ATM call and put\"\n",
    "model_name                = 'Quart_opts_short'\n",
    "position_type             = \"Short\"\n",
    "\n",
    "LSTM_underlying = DeepAgent(train_opts_quart_input.shape[0], batch_size, train_opts_quart_input.shape[2], \n",
    "        loss_type, nbs_assets, position_type, nbs_layers, nbs_units, lr, prepro_stock, \n",
    "        hedging_instruments, alpha, name = model_name)\n",
    "\n",
    "# Start training \n",
    "start = dt.datetime.now()\n",
    "\n",
    "print('---Start training---')\n",
    "with tf.Session() as sess:           \n",
    "    loss_epoch = LSTM_underlying.training(train_opts_quart_input, disc_batch_quart, sess, epochs,\n",
    "                                            Opts_quart_train)\n",
    "    print('---Training end---')\n",
    "        \n",
    "model_predict = DeepAgent(test_opts_quart_input.shape[0], batch_size, test_opts_quart_input.shape[2], \n",
    "        loss_type, nbs_assets, position_type, nbs_layers, nbs_units, lr, prepro_stock, \n",
    "        hedging_instruments, alpha, name = model_name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Load the saved model\n",
    "    model_predict.restore(sess, r\"/Users/alexa/Github files/ERP with multi hedging instruments/Models/%s/models.ckpt\" % model_name)\n",
    "    deltas = model_predict.predict(test_opts_quart_input, disc_test_quart, sess, loss_type, Opts_quart_test)\n",
    "    CVaR_95_short_test_opts_quart = measured_risk_exposures(deltas, test_opts_quart_input, \n",
    "                            disc_test_quart, strike, position_type, hedging_instruments, prepro_stock, Opts_quart_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Training of the long neural network and computation of the long measured risk exposure \n",
    "$$\\epsilon^{(L)}(0) = \\underset{\\delta\\in \\Pi}{\\min} \\, \\rho \\left(-\\Phi(S_{N},Z_{N}) -B_{N}G_{N}^{\\delta}\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.A) With underlying stock - daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Start training---\n",
      "Time elapsed: 0:01:54.108914\n",
      "Epoch 1, CVaR - Train: -0.362\n",
      "Time elapsed: 0:03:32.033170\n",
      "Epoch 2, CVaR - Train: -2.791\n",
      "Time elapsed: 0:05:09.872653\n",
      "Epoch 3, CVaR - Train: -2.986\n",
      "Time elapsed: 0:06:47.689865\n",
      "Epoch 4, CVaR - Train: -3.043\n",
      "Time elapsed: 0:08:25.694130\n",
      "Epoch 5, CVaR - Train: -3.054\n",
      "Time elapsed: 0:10:01.041802\n",
      "Epoch 6, CVaR - Train: -3.040\n",
      "Time elapsed: 0:11:36.438476\n",
      "Epoch 7, CVaR - Train: -2.956\n",
      "Time elapsed: 0:13:14.287705\n",
      "Epoch 8, CVaR - Train: -3.113\n",
      "Time elapsed: 0:14:52.383514\n",
      "Epoch 9, CVaR - Train: -3.164\n",
      "Time elapsed: 0:16:30.112717\n",
      "Epoch 10, CVaR - Train: -3.196\n",
      "Time elapsed: 0:18:07.928938\n",
      "Epoch 11, CVaR - Train: -3.240\n",
      "Time elapsed: 0:19:45.775160\n",
      "Epoch 12, CVaR - Train: -3.271\n",
      "Time elapsed: 0:21:23.699415\n",
      "Epoch 13, CVaR - Train: -3.313\n",
      "Time elapsed: 0:23:01.565648\n",
      "Epoch 14, CVaR - Train: -3.320\n",
      "Time elapsed: 0:24:39.553901\n",
      "Epoch 15, CVaR - Train: -3.337\n",
      "Time elapsed: 0:26:17.281281\n",
      "Epoch 16, CVaR - Train: -3.345\n",
      "Time elapsed: 0:27:55.016485\n",
      "Epoch 17, CVaR - Train: -3.360\n",
      "Time elapsed: 0:29:32.773693\n",
      "Epoch 18, CVaR - Train: -3.367\n",
      "Time elapsed: 0:31:10.466878\n",
      "Epoch 19, CVaR - Train: -3.387\n",
      "Time elapsed: 0:32:48.361128\n",
      "Epoch 20, CVaR - Train: -3.389\n",
      "Time elapsed: 0:34:23.759802\n",
      "Epoch 21, CVaR - Train: -3.388\n",
      "Time elapsed: 0:36:01.716047\n",
      "Epoch 22, CVaR - Train: -3.412\n",
      "Time elapsed: 0:37:37.029710\n",
      "Epoch 23, CVaR - Train: -3.400\n",
      "Time elapsed: 0:39:14.960958\n",
      "Epoch 24, CVaR - Train: -3.416\n",
      "Time elapsed: 0:40:52.770178\n",
      "Epoch 25, CVaR - Train: -3.422\n",
      "Time elapsed: 0:42:28.239869\n",
      "Epoch 26, CVaR - Train: -3.417\n",
      "Time elapsed: 0:44:06.117095\n",
      "Epoch 27, CVaR - Train: -3.425\n",
      "Time elapsed: 0:45:44.088354\n",
      "Epoch 28, CVaR - Train: -3.425\n",
      "Time elapsed: 0:47:21.999597\n",
      "Epoch 29, CVaR - Train: -3.433\n",
      "Time elapsed: 0:48:57.328262\n",
      "Epoch 30, CVaR - Train: -3.431\n",
      "Time elapsed: 0:50:34.919597\n",
      "Epoch 31, CVaR - Train: -3.445\n",
      "Time elapsed: 0:52:10.332272\n",
      "Epoch 32, CVaR - Train: -3.444\n",
      "Time elapsed: 0:53:45.808963\n",
      "Epoch 33, CVaR - Train: -3.444\n",
      "Time elapsed: 0:55:23.572173\n",
      "Epoch 34, CVaR - Train: -3.448\n",
      "Time elapsed: 0:57:01.487418\n",
      "Epoch 35, CVaR - Train: -3.452\n",
      "Time elapsed: 0:58:36.830078\n",
      "Epoch 36, CVaR - Train: -3.448\n",
      "Time elapsed: 1:00:12.279753\n",
      "Epoch 37, CVaR - Train: -3.429\n",
      "Time elapsed: 1:01:47.787602\n",
      "Epoch 38, CVaR - Train: -3.438\n",
      "Time elapsed: 1:03:25.868885\n",
      "Epoch 39, CVaR - Train: -3.455\n",
      "Time elapsed: 1:05:01.280369\n",
      "Epoch 40, CVaR - Train: -3.454\n",
      "Time elapsed: 1:06:39.364662\n",
      "Epoch 41, CVaR - Train: -3.459\n",
      "Time elapsed: 1:08:14.867358\n",
      "Epoch 42, CVaR - Train: -3.452\n",
      "Time elapsed: 1:09:50.321044\n",
      "Epoch 43, CVaR - Train: -3.455\n",
      "Time elapsed: 1:11:25.831743\n",
      "Epoch 44, CVaR - Train: -3.459\n",
      "Time elapsed: 1:13:01.479472\n",
      "Epoch 45, CVaR - Train: -3.336\n",
      "Time elapsed: 1:14:37.094827\n",
      "Epoch 46, CVaR - Train: -3.384\n",
      "Time elapsed: 1:16:14.953057\n",
      "Epoch 47, CVaR - Train: -3.462\n",
      "Time elapsed: 1:17:52.830284\n",
      "Epoch 48, CVaR - Train: -3.468\n",
      "Time elapsed: 1:19:28.331980\n",
      "Epoch 49, CVaR - Train: -3.454\n",
      "Time elapsed: 1:21:03.910705\n",
      "Epoch 50, CVaR - Train: -3.442\n",
      "---Finished training results---\n",
      "Time elapsed: 1:21:03.910705\n",
      "---Training end---\n",
      "INFO:tensorflow:Restoring parameters from /Users/alexa/Github files/ERP with multi hedging instruments/Models/Daily_stock_long/models.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Normalization \n",
    "nbs_assets                = 1\n",
    "hedging_instruments       = \"Stock\"\n",
    "model_name                = 'Daily_stock_long'\n",
    "position_type             = \"Long\"\n",
    "\n",
    "LSTM_underlying = DeepAgent(train_stock_daily_input.shape[0], batch_size, train_stock_daily_input.shape[2], \n",
    "        loss_type, nbs_assets, position_type, nbs_layers, nbs_units, lr, prepro_stock, \n",
    "        hedging_instruments, alpha, name = model_name)\n",
    "\n",
    "# Start training \n",
    "start = dt.datetime.now()\n",
    "\n",
    "print('---Start training---')\n",
    "with tf.Session() as sess:           \n",
    "    loss_epoch = LSTM_underlying.training(train_stock_daily_input, disc_batch_daily, sess, epochs)\n",
    "    print('---Training end---')\n",
    "        \n",
    "model_predict = DeepAgent(test_stock_daily_input.shape[0], batch_size, test_stock_daily_input.shape[2], \n",
    "        loss_type, nbs_assets, position_type, nbs_layers, nbs_units, lr, prepro_stock, \n",
    "        hedging_instruments, alpha, name = model_name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the saved model\n",
    "    model_predict.restore(sess, r\"/Users/alexa/Github files/ERP with multi hedging instruments/Models/%s/models.ckpt\" % model_name)\n",
    "    deltas = model_predict.predict(test_stock_daily_input, disc_test_daily, sess, loss_type)\n",
    "    CVaR_95_long_test_stock_daily = measured_risk_exposures(deltas, test_stock_daily_input, \n",
    "                            disc_test_daily, strike, position_type, hedging_instruments, prepro_stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.B) With underlying stock - month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Start training---\n",
      "Time elapsed: 0:00:05.999924\n",
      "Epoch 1, CVaR - Train: -0.454\n",
      "Time elapsed: 0:00:11.410364\n",
      "Epoch 2, CVaR - Train: -1.816\n",
      "Time elapsed: 0:00:16.797264\n",
      "Epoch 3, CVaR - Train: -1.908\n",
      "Time elapsed: 0:00:22.210824\n",
      "Epoch 4, CVaR - Train: -1.947\n",
      "Time elapsed: 0:00:27.614381\n",
      "Epoch 5, CVaR - Train: -1.963\n",
      "Time elapsed: 0:00:33.024898\n",
      "Epoch 6, CVaR - Train: -1.979\n",
      "Time elapsed: 0:00:38.424125\n",
      "Epoch 7, CVaR - Train: -1.997\n",
      "Time elapsed: 0:00:43.834354\n",
      "Epoch 8, CVaR - Train: -1.999\n",
      "Time elapsed: 0:00:49.244783\n",
      "Epoch 9, CVaR - Train: -2.002\n",
      "Time elapsed: 0:00:54.646999\n",
      "Epoch 10, CVaR - Train: -2.007\n",
      "Time elapsed: 0:01:00.042236\n",
      "Epoch 11, CVaR - Train: -2.019\n",
      "Time elapsed: 0:01:05.318993\n",
      "Epoch 12, CVaR - Train: -2.018\n",
      "Time elapsed: 0:01:10.734472\n",
      "Epoch 13, CVaR - Train: -2.021\n",
      "Time elapsed: 0:01:16.135829\n",
      "Epoch 14, CVaR - Train: -2.023\n",
      "Time elapsed: 0:01:21.528404\n",
      "Epoch 15, CVaR - Train: -2.027\n",
      "Time elapsed: 0:01:26.926795\n",
      "Epoch 16, CVaR - Train: -2.028\n",
      "Time elapsed: 0:01:32.326022\n",
      "Epoch 17, CVaR - Train: -2.029\n",
      "Time elapsed: 0:01:37.719247\n",
      "Epoch 18, CVaR - Train: -2.031\n",
      "Time elapsed: 0:01:43.134477\n",
      "Epoch 19, CVaR - Train: -2.032\n",
      "Time elapsed: 0:01:48.533704\n",
      "Epoch 20, CVaR - Train: -2.033\n",
      "Time elapsed: 0:01:53.935931\n",
      "Epoch 21, CVaR - Train: -2.035\n",
      "Time elapsed: 0:01:59.353162\n",
      "Epoch 22, CVaR - Train: -2.038\n",
      "Time elapsed: 0:02:04.584350\n",
      "Epoch 23, CVaR - Train: -2.036\n",
      "Time elapsed: 0:02:09.830552\n",
      "Epoch 24, CVaR - Train: -2.037\n",
      "Time elapsed: 0:02:15.060740\n",
      "Epoch 25, CVaR - Train: -2.038\n",
      "Time elapsed: 0:02:20.462958\n",
      "Epoch 26, CVaR - Train: -2.039\n",
      "Time elapsed: 0:02:25.864185\n",
      "Epoch 27, CVaR - Train: -2.043\n",
      "Time elapsed: 0:02:31.099374\n",
      "Epoch 28, CVaR - Train: -2.041\n",
      "Time elapsed: 0:02:36.333572\n",
      "Epoch 29, CVaR - Train: -2.042\n",
      "Time elapsed: 0:02:41.722819\n",
      "Epoch 30, CVaR - Train: -2.045\n",
      "Time elapsed: 0:02:46.954008\n",
      "Epoch 31, CVaR - Train: -2.043\n",
      "Time elapsed: 0:02:52.363288\n",
      "Epoch 32, CVaR - Train: -2.045\n",
      "Time elapsed: 0:02:57.768657\n",
      "Epoch 33, CVaR - Train: -2.046\n",
      "Time elapsed: 0:03:03.031853\n",
      "Epoch 34, CVaR - Train: -2.046\n",
      "Time elapsed: 0:03:08.428232\n",
      "Epoch 35, CVaR - Train: -2.047\n",
      "Time elapsed: 0:03:13.825621\n",
      "Epoch 36, CVaR - Train: -2.050\n",
      "Time elapsed: 0:03:19.070237\n",
      "Epoch 37, CVaR - Train: -2.049\n",
      "Time elapsed: 0:03:24.315910\n",
      "Epoch 38, CVaR - Train: -2.046\n",
      "Time elapsed: 0:03:29.718138\n",
      "Epoch 39, CVaR - Train: -2.053\n",
      "Time elapsed: 0:03:34.956531\n",
      "Epoch 40, CVaR - Train: -2.050\n",
      "Time elapsed: 0:03:40.195991\n",
      "Epoch 41, CVaR - Train: -2.049\n",
      "Time elapsed: 0:03:45.434181\n",
      "Epoch 42, CVaR - Train: -2.050\n",
      "Time elapsed: 0:03:50.681373\n",
      "Epoch 43, CVaR - Train: -2.050\n",
      "Time elapsed: 0:03:55.938567\n",
      "Epoch 44, CVaR - Train: -2.050\n",
      "Time elapsed: 0:04:01.352925\n",
      "Epoch 45, CVaR - Train: -2.053\n",
      "Time elapsed: 0:04:06.759153\n",
      "Epoch 46, CVaR - Train: -2.055\n",
      "Time elapsed: 0:04:12.000622\n",
      "Epoch 47, CVaR - Train: -2.052\n",
      "Time elapsed: 0:04:17.249395\n",
      "Epoch 48, CVaR - Train: -2.054\n",
      "Time elapsed: 0:04:22.491798\n",
      "Epoch 49, CVaR - Train: -2.054\n",
      "Time elapsed: 0:04:27.885205\n",
      "Epoch 50, CVaR - Train: -2.057\n",
      "---Finished training results---\n",
      "Time elapsed: 0:04:27.885205\n",
      "---Training end---\n",
      "INFO:tensorflow:Restoring parameters from /Users/alexa/Github files/ERP with multi hedging instruments/Models/Month_stock_long/models.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Normalization \n",
    "nbs_assets                = 1\n",
    "hedging_instruments       = \"Stock\"\n",
    "model_name                = 'Month_stock_long'\n",
    "position_type             = \"Long\"\n",
    "\n",
    "LSTM_underlying = DeepAgent(train_stock_month_input.shape[0], batch_size, train_stock_month_input.shape[2], \n",
    "        loss_type, nbs_assets, position_type, nbs_layers, nbs_units, lr, prepro_stock, \n",
    "        hedging_instruments, alpha, name = model_name)\n",
    "\n",
    "# Start training \n",
    "start = dt.datetime.now()\n",
    "\n",
    "print('---Start training---')\n",
    "with tf.Session() as sess:           \n",
    "    loss_epoch = LSTM_underlying.training(train_stock_month_input, disc_batch_month, sess, epochs)\n",
    "    print('---Training end---')\n",
    "        \n",
    "model_predict = DeepAgent(test_stock_month_input.shape[0], batch_size, test_stock_month_input.shape[2], \n",
    "        loss_type, nbs_assets, position_type, nbs_layers, nbs_units, lr, prepro_stock, \n",
    "        hedging_instruments, alpha, name = model_name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    model_predict.restore(sess, r\"/Users/alexa/Github files/ERP with multi hedging instruments/Models/%s/models.ckpt\" % model_name)\n",
    "    deltas = model_predict.predict(test_stock_month_input, disc_test_month, sess, loss_type)\n",
    "    CVaR_95_long_test_stock_month = measured_risk_exposures(deltas, test_stock_month_input, \n",
    "                            disc_test_month, strike, position_type, hedging_instruments, prepro_stock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.C) With two opts - month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Start training---\n",
      "Time elapsed: 0:00:07.066877\n",
      "Epoch 1, CVaR - Train: -0.477\n",
      "Time elapsed: 0:00:13.537624\n",
      "Epoch 2, CVaR - Train: -3.396\n",
      "Time elapsed: 0:00:20.008914\n",
      "Epoch 3, CVaR - Train: -3.634\n",
      "Time elapsed: 0:00:26.470753\n",
      "Epoch 4, CVaR - Train: -3.756\n",
      "Time elapsed: 0:00:32.959620\n",
      "Epoch 5, CVaR - Train: -3.802\n",
      "Time elapsed: 0:00:39.428027\n",
      "Epoch 6, CVaR - Train: -3.822\n",
      "Time elapsed: 0:00:45.906805\n",
      "Epoch 7, CVaR - Train: -3.830\n",
      "Time elapsed: 0:00:52.369986\n",
      "Epoch 8, CVaR - Train: -3.840\n",
      "Time elapsed: 0:00:58.841594\n",
      "Epoch 9, CVaR - Train: -3.856\n",
      "Time elapsed: 0:01:05.313483\n",
      "Epoch 10, CVaR - Train: -3.860\n",
      "Time elapsed: 0:01:11.598037\n",
      "Epoch 11, CVaR - Train: -3.852\n",
      "Time elapsed: 0:01:18.079499\n",
      "Epoch 12, CVaR - Train: -3.869\n",
      "Time elapsed: 0:01:24.383941\n",
      "Epoch 13, CVaR - Train: -3.865\n",
      "Time elapsed: 0:01:30.851401\n",
      "Epoch 14, CVaR - Train: -3.875\n",
      "Time elapsed: 0:01:37.313868\n",
      "Epoch 15, CVaR - Train: -3.884\n",
      "Time elapsed: 0:01:43.615300\n",
      "Epoch 16, CVaR - Train: -3.876\n",
      "Time elapsed: 0:01:50.078779\n",
      "Epoch 17, CVaR - Train: -3.886\n",
      "Time elapsed: 0:01:56.544705\n",
      "Epoch 18, CVaR - Train: -3.890\n",
      "Time elapsed: 0:02:03.002916\n",
      "Epoch 19, CVaR - Train: -3.894\n",
      "Time elapsed: 0:02:09.295257\n",
      "Epoch 20, CVaR - Train: -3.893\n",
      "Time elapsed: 0:02:15.754725\n",
      "Epoch 21, CVaR - Train: -3.897\n",
      "Time elapsed: 0:02:22.214332\n",
      "Epoch 22, CVaR - Train: -3.899\n",
      "Time elapsed: 0:02:28.683223\n",
      "Epoch 23, CVaR - Train: -3.904\n",
      "Time elapsed: 0:02:34.980818\n",
      "Epoch 24, CVaR - Train: -3.902\n",
      "Time elapsed: 0:02:41.265433\n",
      "Epoch 25, CVaR - Train: -3.902\n",
      "Time elapsed: 0:02:47.724165\n",
      "Epoch 26, CVaR - Train: -3.917\n",
      "Time elapsed: 0:02:54.013816\n",
      "Epoch 27, CVaR - Train: -3.906\n",
      "Time elapsed: 0:03:00.475300\n",
      "Epoch 28, CVaR - Train: -3.919\n",
      "Time elapsed: 0:03:06.768866\n",
      "Epoch 29, CVaR - Train: -3.918\n",
      "Time elapsed: 0:03:13.046294\n",
      "Epoch 30, CVaR - Train: -3.913\n",
      "Time elapsed: 0:03:19.342138\n",
      "Epoch 31, CVaR - Train: -3.919\n",
      "Time elapsed: 0:03:25.808596\n",
      "Epoch 32, CVaR - Train: -3.928\n",
      "Time elapsed: 0:03:32.090910\n",
      "Epoch 33, CVaR - Train: -3.927\n",
      "Time elapsed: 0:03:38.555491\n",
      "Epoch 34, CVaR - Train: -3.930\n",
      "Time elapsed: 0:03:45.037197\n",
      "Epoch 35, CVaR - Train: -3.931\n",
      "Time elapsed: 0:03:51.520542\n",
      "Epoch 36, CVaR - Train: -3.936\n",
      "Time elapsed: 0:03:57.830221\n",
      "Epoch 37, CVaR - Train: -3.932\n",
      "Time elapsed: 0:04:04.127196\n",
      "Epoch 38, CVaR - Train: -3.930\n",
      "Time elapsed: 0:04:10.596962\n",
      "Epoch 39, CVaR - Train: -3.937\n",
      "Time elapsed: 0:04:17.048581\n",
      "Epoch 40, CVaR - Train: -3.942\n",
      "Time elapsed: 0:04:23.347462\n",
      "Epoch 41, CVaR - Train: -3.942\n",
      "Time elapsed: 0:04:29.637282\n",
      "Epoch 42, CVaR - Train: -3.940\n",
      "Time elapsed: 0:04:35.933850\n",
      "Epoch 43, CVaR - Train: -3.941\n",
      "Time elapsed: 0:04:42.242706\n",
      "Epoch 44, CVaR - Train: -3.941\n",
      "Time elapsed: 0:04:48.713290\n",
      "Epoch 45, CVaR - Train: -3.944\n",
      "Time elapsed: 0:04:55.194911\n",
      "Epoch 46, CVaR - Train: -3.949\n",
      "Time elapsed: 0:05:01.503594\n",
      "Epoch 47, CVaR - Train: -3.940\n",
      "Time elapsed: 0:05:07.812170\n",
      "Epoch 48, CVaR - Train: -3.940\n",
      "Time elapsed: 0:05:14.110065\n",
      "Epoch 49, CVaR - Train: -3.948\n",
      "Time elapsed: 0:05:20.400835\n",
      "Epoch 50, CVaR - Train: -3.948\n",
      "---Finished training results---\n",
      "Time elapsed: 0:05:20.400835\n",
      "---Training end---\n",
      "INFO:tensorflow:Restoring parameters from /Users/alexa/Github files/ERP with multi hedging instruments/Models/Month_opts_long/models.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Normalization \n",
    "nbs_assets                = 2\n",
    "hedging_instruments       = \"ATM call and put\"\n",
    "model_name                = 'Month_opts_long'\n",
    "position_type             = \"Long\"\n",
    "\n",
    "LSTM_underlying = DeepAgent(train_opts_month_input.shape[0], batch_size, train_opts_month_input.shape[2], \n",
    "        loss_type, nbs_assets, position_type, nbs_layers, nbs_units, lr, prepro_stock, \n",
    "        hedging_instruments, alpha, name = model_name)\n",
    "\n",
    "# Start training \n",
    "start = dt.datetime.now()\n",
    "\n",
    "print('---Start training---')\n",
    "with tf.Session() as sess:           \n",
    "    loss_epoch = LSTM_underlying.training(train_opts_month_input, disc_batch_month, sess, epochs,\n",
    "                                            Opts_month_train)\n",
    "    print('---Training end---')\n",
    "        \n",
    "model_predict = DeepAgent(test_opts_month_input.shape[0], batch_size, test_opts_month_input.shape[2], \n",
    "        loss_type, nbs_assets, position_type, nbs_layers, nbs_units, lr, prepro_stock, \n",
    "        hedging_instruments, alpha, name = model_name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Load the saved model\n",
    "    model_predict.restore(sess, r\"/Users/alexa/Github files/ERP with multi hedging instruments/Models/%s/models.ckpt\" % model_name)\n",
    "    deltas = model_predict.predict(test_opts_month_input, disc_test_month, sess, loss_type, Opts_month_test)\n",
    "    CVaR_95_long_test_opts_month = measured_risk_exposures(deltas, test_opts_month_input, \n",
    "                            disc_test_month, strike, position_type, hedging_instruments, prepro_stock, Opts_month_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.D) With two opts - quarterly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Start training---\n",
      "Time elapsed: 0:00:02.899668\n",
      "Epoch 1, CVaR - Train: -0.159\n",
      "Time elapsed: 0:00:05.567522\n",
      "Epoch 2, CVaR - Train: -3.003\n",
      "Time elapsed: 0:00:08.224564\n",
      "Epoch 3, CVaR - Train: -3.215\n",
      "Time elapsed: 0:00:10.881459\n",
      "Epoch 4, CVaR - Train: -3.289\n",
      "Time elapsed: 0:00:13.532667\n",
      "Epoch 5, CVaR - Train: -3.327\n",
      "Time elapsed: 0:00:16.175504\n",
      "Epoch 6, CVaR - Train: -3.339\n",
      "Time elapsed: 0:00:18.841496\n",
      "Epoch 7, CVaR - Train: -3.342\n",
      "Time elapsed: 0:00:21.489474\n",
      "Epoch 8, CVaR - Train: -3.352\n",
      "Time elapsed: 0:00:24.144387\n",
      "Epoch 9, CVaR - Train: -3.358\n",
      "Time elapsed: 0:00:26.709458\n",
      "Epoch 10, CVaR - Train: -3.355\n",
      "Time elapsed: 0:00:29.269039\n",
      "Epoch 11, CVaR - Train: -3.358\n",
      "Time elapsed: 0:00:31.916814\n",
      "Epoch 12, CVaR - Train: -3.361\n",
      "Time elapsed: 0:00:34.568692\n",
      "Epoch 13, CVaR - Train: -3.367\n",
      "Time elapsed: 0:00:37.227510\n",
      "Epoch 14, CVaR - Train: -3.371\n",
      "Time elapsed: 0:00:39.886132\n",
      "Epoch 15, CVaR - Train: -3.375\n",
      "Time elapsed: 0:00:42.449046\n",
      "Epoch 16, CVaR - Train: -3.375\n",
      "Time elapsed: 0:00:45.014803\n",
      "Epoch 17, CVaR - Train: -3.372\n",
      "Time elapsed: 0:00:47.581825\n",
      "Epoch 18, CVaR - Train: -3.374\n",
      "Time elapsed: 0:00:50.230566\n",
      "Epoch 19, CVaR - Train: -3.380\n",
      "Time elapsed: 0:00:52.803140\n",
      "Epoch 20, CVaR - Train: -3.377\n",
      "Time elapsed: 0:00:55.446750\n",
      "Epoch 21, CVaR - Train: -3.381\n",
      "Time elapsed: 0:00:58.105894\n",
      "Epoch 22, CVaR - Train: -3.389\n",
      "Time elapsed: 0:01:00.664637\n",
      "Epoch 23, CVaR - Train: -3.385\n",
      "Time elapsed: 0:01:03.327764\n",
      "Epoch 24, CVaR - Train: -3.395\n",
      "Time elapsed: 0:01:05.908592\n",
      "Epoch 25, CVaR - Train: -3.386\n",
      "Time elapsed: 0:01:08.480504\n",
      "Epoch 26, CVaR - Train: -3.390\n",
      "Time elapsed: 0:01:11.131374\n",
      "Epoch 27, CVaR - Train: -3.396\n",
      "Time elapsed: 0:01:13.696390\n",
      "Epoch 28, CVaR - Train: -3.388\n",
      "Time elapsed: 0:01:16.254248\n",
      "Epoch 29, CVaR - Train: -3.394\n",
      "Time elapsed: 0:01:18.814956\n",
      "Epoch 30, CVaR - Train: -3.395\n",
      "Time elapsed: 0:01:21.378529\n",
      "Epoch 31, CVaR - Train: -3.393\n",
      "Time elapsed: 0:01:24.033281\n",
      "Epoch 32, CVaR - Train: -3.400\n",
      "Time elapsed: 0:01:26.598075\n",
      "Epoch 33, CVaR - Train: -3.399\n",
      "Time elapsed: 0:01:29.253372\n",
      "Epoch 34, CVaR - Train: -3.401\n",
      "Time elapsed: 0:01:31.903265\n",
      "Epoch 35, CVaR - Train: -3.402\n",
      "Time elapsed: 0:01:34.565432\n",
      "Epoch 36, CVaR - Train: -3.405\n",
      "Time elapsed: 0:01:37.122013\n",
      "Epoch 37, CVaR - Train: -3.404\n",
      "Time elapsed: 0:01:39.681240\n",
      "Epoch 38, CVaR - Train: -3.404\n",
      "Time elapsed: 0:01:42.350273\n",
      "Epoch 39, CVaR - Train: -3.408\n",
      "Time elapsed: 0:01:44.909949\n",
      "Epoch 40, CVaR - Train: -3.408\n",
      "Time elapsed: 0:01:47.506682\n",
      "Epoch 41, CVaR - Train: -3.407\n",
      "Time elapsed: 0:01:50.084268\n",
      "Epoch 42, CVaR - Train: -3.408\n",
      "Time elapsed: 0:01:52.664133\n",
      "Epoch 43, CVaR - Train: -3.408\n",
      "Time elapsed: 0:01:55.318974\n",
      "Epoch 44, CVaR - Train: -3.411\n",
      "Time elapsed: 0:01:57.968866\n",
      "Epoch 45, CVaR - Train: -3.412\n",
      "Time elapsed: 0:02:00.535449\n",
      "Epoch 46, CVaR - Train: -3.410\n",
      "Time elapsed: 0:02:03.196043\n",
      "Epoch 47, CVaR - Train: -3.412\n",
      "Time elapsed: 0:02:05.844660\n",
      "Epoch 48, CVaR - Train: -3.413\n",
      "Time elapsed: 0:02:08.508265\n",
      "Epoch 49, CVaR - Train: -3.414\n",
      "Time elapsed: 0:02:11.183875\n",
      "Epoch 50, CVaR - Train: -3.414\n",
      "---Finished training results---\n",
      "Time elapsed: 0:02:11.183875\n",
      "---Training end---\n",
      "INFO:tensorflow:Restoring parameters from /Users/alexa/Github files/ERP with multi hedging instruments/Models/Quart_opts_short/models.ckpt\n"
     ]
    }
   ],
   "source": [
    "# Normalization \n",
    "nbs_assets                = 2\n",
    "hedging_instruments       = \"ATM call and put\"\n",
    "model_name                = 'Quart_opts_short'\n",
    "position_type             = \"Long\"\n",
    "\n",
    "LSTM_underlying = DeepAgent(train_opts_quart_input.shape[0], batch_size, train_opts_quart_input.shape[2], \n",
    "        loss_type, nbs_assets, position_type, nbs_layers, nbs_units, lr, prepro_stock, \n",
    "        hedging_instruments, alpha, name = model_name)\n",
    "\n",
    "# Start training \n",
    "start = dt.datetime.now()\n",
    "\n",
    "print('---Start training---')\n",
    "with tf.Session() as sess:           \n",
    "    loss_epoch = LSTM_underlying.training(train_opts_quart_input, disc_batch_quart, sess, epochs,\n",
    "                                            Opts_quart_train)\n",
    "    print('---Training end---')\n",
    "        \n",
    "model_predict = DeepAgent(test_opts_quart_input.shape[0], batch_size, test_opts_quart_input.shape[2], \n",
    "        loss_type, nbs_assets, position_type, nbs_layers, nbs_units, lr, prepro_stock, \n",
    "        hedging_instruments, alpha, name = model_name)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Load the saved model\n",
    "    model_predict.restore(sess, r\"/Users/alexa/Github files/ERP with multi hedging instruments/Models/%s/models.ckpt\" % model_name)\n",
    "    deltas = model_predict.predict(test_opts_quart_input, disc_test_quart, sess, loss_type, Opts_quart_test)\n",
    "    CVaR_95_long_test_opts_quart = measured_risk_exposures(deltas, test_opts_quart_input, \n",
    "                            disc_test_quart, strike, position_type, hedging_instruments, prepro_stock, Opts_quart_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Compute equal risk option prices $C_{0}^{\\star}$ and incompleteness measure $\\epsilon^{\\star}$ with the results of the test set for all four cases\n",
    "$$C_{0}^{\\star} = \\frac{\\epsilon^{(S)}(0) - \\epsilon^{(L)}(0)}{2B_{N}}, \\quad \\epsilon^{\\star} = \\frac{\\epsilon^{(L)}(0) + \\epsilon^{(S)}(0)}{2}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "Daily stock hedging results:\n",
      "Equal risk price of ATM put of 60 days: 6.0416\n",
      "Residual hedging risk of ATM put of 60 days: 2.7642\n",
      "----------------------------------------------------\n",
      "Monthly stock hedging results:\n",
      "Equal risk price of ATM put of 60 days: 5.7291\n",
      "Residual hedging risk of ATM put of 60 days: 3.8417\n",
      "----------------------------------------------------\n",
      "1-month opts hedging results:\n",
      "Equal risk price of ATM put of 60 days: 5.5215\n",
      "Residual hedging risk of ATM put of 60 days: 1.7542\n",
      "----------------------------------------------------\n",
      "3-months opts hedging results:\n",
      "Equal risk price of ATM put of 60 days: 5.1450\n",
      "Residual hedging risk of ATM put of 60 days: 1.8853\n"
     ]
    }
   ],
   "source": [
    "# A) Daily stock\n",
    "ERP_stock_daily     = (CVaR_95_short_test_stock_daily - CVaR_95_long_test_stock_daily)/(2*np.exp(r*T))\n",
    "epsilon_stock_daily = (CVaR_95_long_test_stock_daily + CVaR_95_short_test_stock_daily)/2\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Daily stock hedging results:\")\n",
    "print(\"Equal risk price of ATM put of 60 days: %.4f\" %(ERP_stock_daily))\n",
    "print(\"Residual hedging risk of ATM put of 60 days: %.4f\" %(epsilon_stock_daily))\n",
    "\n",
    "# B) month stock\n",
    "ERP_stock_month     = (CVaR_95_short_test_stock_month - CVaR_95_long_test_stock_month)/(2*np.exp(r*T))\n",
    "epsilon_stock_month = (CVaR_95_long_test_stock_month + CVaR_95_short_test_stock_month)/2\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"Monthly stock hedging results:\")\n",
    "print(\"Equal risk price of ATM put of 60 days: %.4f\" %(ERP_stock_month))\n",
    "print(\"Residual hedging risk of ATM put of 60 days: %.4f\" %(epsilon_stock_month))\n",
    "\n",
    "# C) month opts\n",
    "ERP_opts_month     = (CVaR_95_short_test_opts_month - CVaR_95_long_test_opts_month)/(2*np.exp(r*T))\n",
    "epsilon_opts_month = (CVaR_95_long_test_opts_month + CVaR_95_short_test_opts_month)/2\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"1-month opts hedging results:\")\n",
    "print(\"Equal risk price of ATM put of 60 days: %.4f\" %(ERP_opts_month))\n",
    "print(\"Residual hedging risk of ATM put of 60 days: %.4f\" %(epsilon_opts_month))\n",
    "\n",
    "# D) Quarterly opts\n",
    "ERP_opts_quarterly     = (CVaR_95_short_test_opts_quart - CVaR_95_long_test_opts_quart)/(2*np.exp(r*T))\n",
    "epsilon_opts_quarterly = (CVaR_95_long_test_opts_quart + CVaR_95_short_test_opts_quart)/2\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"3-months opts hedging results:\")\n",
    "print(\"Equal risk price of ATM put of 60 days: %.4f\" %(ERP_opts_quarterly))\n",
    "print(\"Residual hedging risk of ATM put of 60 days: %.4f\" %(epsilon_opts_quarterly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References\n",
    "- Buehler, H., Gonon, L., Teichmann, J., and Wood, B. (2019). Deep hedging. Quantitative Finance, 19(8):1271-1291.\n",
    "- Carbonneau, A. and Godin, F. (2020). Equal risk pricing of derivatives with deep hedging. Quantitative Finance, pages 1-16.\n",
    "- Carbonneau, A. and Godin, F. (2021). Deep Equal Risk Pricing of Financial Derivatives with Multiple Hedging Instruments. arXiv preprint arXiv:2102.12694."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
